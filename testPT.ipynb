{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2673e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.colors as pc\n",
    "\n",
    "from typing import Sequence, Optional, Callable, List, Dict\n",
    "\n",
    "from visuEmbedding import interactive_embedding_plot_3D, components_to_fig_3D, components_to_fig_3D_animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5809cf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([1, 2, 3].extend([4, 5, 6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0290109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_normalized_gradients(\n",
    "    embeddings,\n",
    "    gradients=None,\n",
    "    embeddings_after:List=[],\n",
    "    labels=[],\n",
    "    labels_after=None,\n",
    "    visual_length=0.5,\n",
    "    word_to_display:Optional[List]=None,\n",
    "    _min=None,\n",
    "    _max=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualizes embeddings and gradients in 3D using Plotly.\n",
    "    Gradients are normalized to a fixed visual length to act as direction indicators.\n",
    "\n",
    "    \"\"\"\n",
    "    fig = go.Figure()\n",
    "    if _min is None or _max is None:\n",
    "        all_data = embeddings_after + [embeddings]\n",
    "        combined = np.vstack(all_data)\n",
    "        max_abs_val = np.max(np.abs(combined))\n",
    "            \n",
    "        limit = max_abs_val * 1.1\n",
    "        if _min is None:\n",
    "            _min = -limit\n",
    "        if _max is None:\n",
    "            _max = limit\n",
    "    # if gradients is not None:\n",
    "    #     grad_norms = np.linalg.norm(gradients, axis=1, keepdims=True)\n",
    "    #     grad_norms[grad_norms == 0] = 1.0\n",
    "    #     normalized_grads = (gradients / grad_norms) * visual_length\n",
    "    #     normalized_grads = (gradients / grad_norms) * visual_length\n",
    "    \n",
    "    nb_label = len(labels)\n",
    "    for i, emb in enumerate(embeddings):\n",
    "        label = labels[i] if i < nb_label else i\n",
    "        to_dis = (word_to_display is None or label in word_to_display)\n",
    "            \n",
    "        fig.add_trace(\n",
    "            go.Scatter3d(\n",
    "                x=[0, emb[0]],\n",
    "                y=[0, emb[1]],\n",
    "                z=[0, emb[2]],\n",
    "                mode=\"lines+markers+text\",\n",
    "                marker=dict(size=3, color=\"black\"),\n",
    "                line=dict(color=\"gray\", width=5),\n",
    "                name=f\"{label}\",\n",
    "                legendgroup=\"group_start\",\n",
    "                legendgrouptitle_text=\"Initial State\" if i == 0 else None, # Titre du groupe\n",
    "                text=[\"\", label],\n",
    "                textposition=\"top center\",\n",
    "                textfont=dict(size=15, color=\"black\"),\n",
    "                hoverinfo=\"none\",\n",
    "                visible=True if to_dis else 'legendonly'\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if gradients is None:\n",
    "            continue\n",
    "        \n",
    "        grad_vis = gradients[i]\n",
    "        grad_end = (emb + grad_vis * visual_length)\n",
    "        real_grad_norm = np.linalg.norm(gradients[i])  # Actual magnitude for hover info\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter3d(\n",
    "                x=[emb[0], grad_end[0]],\n",
    "                y=[emb[1], grad_end[1]],\n",
    "                z=[emb[2], grad_end[2]],\n",
    "                mode=\"lines\",\n",
    "                line=dict(color=\"red\", width=4),\n",
    "                showlegend=False,\n",
    "                hoverinfo=\"text\",\n",
    "                text=f\"Gradient Strength: {real_grad_norm:.4f}\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Cone(\n",
    "                x=[grad_end[0]],\n",
    "                y=[grad_end[1]],\n",
    "                z=[grad_end[2]],\n",
    "                u=[grad_vis[0]],\n",
    "                v=[grad_vis[1]],\n",
    "                w=[grad_vis[2]],\n",
    "                showscale=False,\n",
    "                sizemode=\"absolute\",\n",
    "                sizeref=0.5,  # Controls size of the arrow head\n",
    "                anchor=\"tip\",  # Tip of cone is at the end of the line\n",
    "                colorscale=[[0, \"red\"], [1, \"red\"]],\n",
    "                name=\"Gradient Dir\",\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    for i, embedding in enumerate(embeddings_after):\n",
    "        group_name = labels_after[i] if labels_after else i\n",
    "        \n",
    "        for j in range(len(embedding)):\n",
    "            label = labels[j] if j < nb_label else j\n",
    "            to_dis = (word_to_display is None or label in word_to_display)\n",
    "            \n",
    "            scale_val = 0.3 + 0.7 * (i / (len(embeddings_after) - 1)) if len(embeddings_after) > 1 else 1\n",
    "            color_code = pc.sample_colorscale('Viridis', [scale_val])[0]\n",
    "            \n",
    "            emb = embedding[j]\n",
    "\n",
    "            fig.add_trace(\n",
    "                go.Scatter3d(\n",
    "                    x=[0, emb[0]],\n",
    "                    y=[0, emb[1]],\n",
    "                    z=[0, emb[2]],\n",
    "                    mode=\"lines+markers+text\",\n",
    "                    name=label,\n",
    "                    text=[\"\", label],\n",
    "                    textposition=\"top center\",\n",
    "                    legendgroup=group_name,\n",
    "                    legendgrouptitle_text=group_name if j == 0 else None,\n",
    "                    marker=dict(size=3, color=\"red\"),\n",
    "                    line=dict(color=color_code, width=5),\n",
    "                    visible=True if to_dis else 'legendonly'\n",
    "                )\n",
    "            )\n",
    "\n",
    "    fig.update_layout(\n",
    "        width=1000,\n",
    "        height=800,\n",
    "        title=\"3D Gradient Direction (Normalized Length)\",\n",
    "        scene=dict(\n",
    "            xaxis=dict(nticks=4, range=[_min, _max], title=\"X\"),\n",
    "            yaxis=dict(nticks=4, range=[_min, _max], title=\"Y\"),\n",
    "            zaxis=dict(nticks=4, range=[_min, _max], title=\"Z\"),\n",
    "        ),\n",
    "        scene_aspectmode=\"cube\",\n",
    "        legend=dict(\n",
    "            groupclick=\"toggleitem\"\n",
    "        )\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289a9984",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [[\"a\", \"aaezfee\" , \"1zefczc\", \"TRZ\", \"f\", \"0\", \"c\", \"89\"]]\n",
    "\n",
    "all_str = [t for s in l for t in s if t.isalpha()]\n",
    "print(all_str)\n",
    "it = iter(l[0])\n",
    "for x, y in zip(it, it):\n",
    "    print(x, y)\n",
    "    \n",
    "    \n",
    "d = {\n",
    "    \"a\": 1,\n",
    "    \"b\": 3,\n",
    "    \"c\": 2\n",
    "}\n",
    "\n",
    "d2 = {\n",
    "    1 : \"guessed\",\n",
    "    145: \"inside\",\n",
    "    23 : \"Look\",\n",
    "    21 : \"Now\",\n",
    "    89 : \"get\",\n",
    "    65 : \"aren\",\n",
    "    23 : \"wait\",\n",
    "    90 : \"numpy\",\n",
    "    12 : \"at\",\n",
    "    34 : \"the\",\n",
    "    \n",
    "}\n",
    "    \n",
    "l = dict(sorted(d2.items())).values()\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730a9379",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(np.array(1)))\n",
    "\n",
    "A = np.ones((3,5))\n",
    "print(A)\n",
    "\n",
    "B = np.zeros(A.shape)\n",
    "print(B)\n",
    "\n",
    "print(np.concatenate((A, B), axis=0))\n",
    "\n",
    "listest = [A]\n",
    "listest.append(B)\n",
    "\n",
    "print(listest)\n",
    "\n",
    "\n",
    "tensorToMult = torch.tensor([1, 2, 2]) * 3\n",
    "print(tensorToMult)\n",
    "\n",
    "print(\"dot product : \", torch.tensor([1, 2, 2]).dot(torch.tensor([0, -2, 2])))\n",
    "print(\"sum *, dim=1 : \", torch.sum(torch.tensor([[1, 2, 2], [2, 1, 2]]) * torch.tensor([[0, -2, 2], [3, 0, -2]]), dim=1))\n",
    "\n",
    "print(\"unsqueeze : \", torch.tensor([[1, 2, 2], [2, 1, 2]]).unsqueeze(-1))\n",
    "print(\"size unsqueeze : \", torch.tensor([[1, 2, 2], [2, 1, 2]]).unsqueeze(0).size())\n",
    "\n",
    "print('bmm : ', )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d933e6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cosine_similarity([[0, 0, 0]], [[0, 0.4, 1]]))\n",
    "print(cosine_similarity([[0, 0.4, 1]], [[1, 0, 1]]))\n",
    "print(cosine_similarity([[1, 0, 1]], [[0, 0.4, 1]]))\n",
    "print(cosine_similarity([[1, 0, 0]], [[-1, 0, 0]]))\n",
    "\n",
    "\n",
    "tensor1 = torch.tensor([1, 2, 3])\n",
    "tensor2 = torch.tensor([7, 8, 9])\n",
    "\n",
    "print(tensor1 * tensor2)\n",
    "\n",
    "tensor3 = torch.tensor([[7., 8., 9.], [0., 1., 0.], [0., 0., 1.]])\n",
    "\n",
    "torch.linalg.vector_norm(tensor3, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1535abab",
   "metadata": {},
   "outputs": [],
   "source": [
    "man = torch.tensor([1, 0, 0], dtype=float)\n",
    "woman = torch.tensor([1, 1, 0], dtype=float)\n",
    "king = torch.tensor([1, 0, 1], dtype=float)\n",
    "\n",
    "grad_man = torch.tensor([0.4621, 0.7311, -0.2689], dtype=float)\n",
    "grad_woman = torch.tensor([0.7311, 0.0000, 0.0000], dtype=float)\n",
    "grad_king = torch.tensor([-0.2689, -0.0000, -0.0000], dtype=float)\n",
    "\n",
    "man2 = torch.tensor([0.5, 0, 0], dtype=float)\n",
    "woman2 = torch.tensor([1, 3, 4], dtype=float)\n",
    "king2 = torch.tensor([1, 0, 1], dtype=float)\n",
    "\n",
    "man3 = torch.tensor([0.1, 0, 10], dtype=float)\n",
    "woman3 = torch.tensor([3, 4, 0], dtype=float)\n",
    "king3 = torch.tensor([1, 0, 1], dtype=float)\n",
    "\n",
    "# Stack them\n",
    "emb_weights = torch.stack([man, woman, king]).numpy()\n",
    "grads = torch.stack([grad_man, grad_woman, grad_king]).numpy()\n",
    "emb_after2 = torch.stack([man2, woman2, king2]).numpy()\n",
    "emb_after3 = torch.stack([man3, woman3, king3]).numpy()\n",
    "\n",
    "print(grads)\n",
    "labels = [\"man\", \"woman\", \"king\", \"queen\"]\n",
    "\n",
    "visualize_normalized_gradients(\n",
    "    emb_weights,\n",
    "    grads,\n",
    "    embeddings_after=[emb_after2, emb_after3],\n",
    "    labels=labels,\n",
    "    word_to_display=[\"man\"],\n",
    "    visual_length=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea38f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_init = nn.Embedding(10, 3)\n",
    "emb_init.weight.data.uniform_(-1, 1)\n",
    "facteur = 1\n",
    "# with torch.no_grad():\n",
    "#     emb_init.weight[0] = torch.tensor([5, 0, -1], dtype=float, requires_grad=True) * facteur # Man\n",
    "#     emb_init.weight[1] = torch.tensor([-5, 0, 1], dtype=float, requires_grad=True) * facteur # Woman\n",
    "#     emb_init.weight[2] = torch.tensor([5, 5, 1], dtype=float, requires_grad=True) * facteur # King\n",
    "#     emb_init.weight[3] = torch.tensor([5, -5, -1], dtype=float, requires_grad=True) * facteur # Farmer\n",
    "    \n",
    "    \n",
    "# visualize_normalized_gradients(\n",
    "#     embeddings=emb_init.weight.detach().numpy(), \n",
    "#     embeddings_after=[],\n",
    "#     labels=[\"homme\", \"femme\", \"roi\", \"fermier\"],\n",
    "#     word_to_display=[\"homme\", \"femme\", \"roi\", \"fermier\"],\n",
    "#     gradients=None, labels_after=None,\n",
    "# )\n",
    "\n",
    "# print(\"Similar pair :\")\n",
    "# print(f\"Loss for man and king : {F.logsigmoid(emb_init.weight[0].dot(emb_init.weight[2]))} \\\n",
    "#       (dot product {emb_init.weight[0].dot(emb_init.weight[2])})\")\n",
    "# print(f\"Loss for man and farmer : {F.logsigmoid(emb_init.weight[0].dot(emb_init.weight[3]))} \\\n",
    "#       (dot product {emb_init.weight[0].dot(emb_init.weight[3])})\")\n",
    "\n",
    "# print(\"Disimilar pair :\")\n",
    "# print(f\"Loss for king and farmer : {F.logsigmoid(emb_init.weight[2].dot(-emb_init.weight[3]))} \\\n",
    "#       (dot product {emb_init.weight[2].dot(-emb_init.weight[3])})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024416d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = deepcopy(emb_init)\n",
    "emb2 = deepcopy(emb_init)\n",
    "emb3 = deepcopy(emb_init)\n",
    "\n",
    "histo = [deepcopy(emb.weight.detach().numpy())]\n",
    "histo2 = [deepcopy(emb2.weight.detach().numpy())]\n",
    "histo3 = [deepcopy(emb3.weight.detach().numpy())]\n",
    "\n",
    "emb = deepcopy(emb_init)\n",
    "emb2 = deepcopy(emb_init)\n",
    "emb3 = deepcopy(emb_init)\n",
    "\n",
    "# opti = torch.optim.Adam(emb.parameters(), lr=10.8)\n",
    "# opti2 = torch.optim.Adam(emb2.parameters(), lr=10.8)\n",
    "# opti3 = torch.optim.Adam(emb3.parameters(), lr=10.8)\n",
    "\n",
    "opti = torch.optim.SGD(emb.parameters(), lr=0.8)\n",
    "opti2 = torch.optim.SGD(emb2.parameters(), lr=0.8)\n",
    "opti3 = torch.optim.SGD(emb3.parameters(), lr=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbaf1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = (F.cosine_similarity(emb.weight, emb.weight))\n",
    "print(loss)\n",
    "cosine_similarity(emb.weight.detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5430143a",
   "metadata": {},
   "outputs": [],
   "source": [
    "opti.zero_grad()\n",
    "opti2.zero_grad()\n",
    "opti3.zero_grad()\n",
    "\n",
    "############################################################ Batch (moyen grad)\n",
    "loss = -(F.logsigmoid(torch.sum(emb(torch.tensor([0, 1])) * emb(torch.tensor([2, 2])), dim=1))).mean()\n",
    "print(\"Batch Loss : \", loss)\n",
    "loss.backward()\n",
    "print('here')\n",
    "print(emb.weight.grad)\n",
    "opti.step()\n",
    "histo.append(deepcopy(emb.weight.detach().numpy()))\n",
    "\n",
    "############################################################ Epoch\n",
    "loss = -F.logsigmoid(torch.sum(emb2(torch.tensor([0])) * emb2(torch.tensor([2])), dim=1))\n",
    "print(\"Epoch Loss (1): \", loss)\n",
    "loss.backward()\n",
    "opti2.step()\n",
    "opti2.zero_grad()\n",
    "loss = -F.logsigmoid(torch.sum(emb2(torch.tensor([1])) * emb2(torch.tensor([2])), dim=1))\n",
    "print(\"Epoch Loss (2) : \", loss)\n",
    "loss.backward()\n",
    "opti2.step()\n",
    "histo2.append(deepcopy(emb2.weight.detach().numpy()))\n",
    "\n",
    "############################################################ Sum\n",
    "loss = -(F.logsigmoid(torch.sum(emb3(torch.tensor([0])) * emb3(torch.tensor([2])), dim=1)) \n",
    "         + F.logsigmoid(torch.sum(emb3(torch.tensor([1])) * emb3(torch.tensor([2])), dim=1))).mean()\n",
    "print(\"Sum Loss : \", loss)\n",
    "loss.backward()\n",
    "\n",
    "opti3.step()\n",
    "histo3.append(deepcopy(emb3.weight.detach().numpy()))\n",
    "\n",
    "############################################################ Poids\n",
    "print(\"Weight init :\")\n",
    "print(emb_init.weight.detach().numpy()[0:3])\n",
    "print(\"Weight after batch :\")\n",
    "print(emb.weight.detach().numpy()[0:3])\n",
    "print(\"Weight after epoch by epoch :\")\n",
    "print(emb2.weight.detach().numpy()[0:3])\n",
    "print(\"Weight after sum of loss :\")\n",
    "print(emb3.weight.detach().numpy()[0:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97983773",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_normalized_gradients(\n",
    "    embeddings=emb_init.weight.detach().numpy(), \n",
    "    embeddings_after=[histo[-1], histo2[-1], histo3[-1]],\n",
    "    labels=[\"homme\", \"femme\", \"roi\"],\n",
    "    word_to_display=[\"homme\", \"femme\", \"roi\"],\n",
    "    gradients=None, labels_after=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11d8df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_normalized_gradients(\n",
    "    embeddings=emb_init.weight.detach().numpy(), \n",
    "    embeddings_after=histo3,\n",
    "    labels=[\"homme\", \"femme\", \"roi\"],\n",
    "    word_to_display=[\"homme\", \"femme\", \"roi\"],\n",
    "    gradients=None, labels_after=None,\n",
    ")\n",
    "    # embeddings=histo3[-2], \n",
    "    # embeddings_after=[histo3[-1]],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e162a1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise SystemError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4447782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"grad :\", emb3.weight.grad)\n",
    "print(\"grad :\", emb2.weight.grad)\n",
    "\n",
    "loss = -(F.logsigmoid(torch.sum(emb3(torch.tensor([0])) * emb3(torch.tensor([2])), dim=1)) \n",
    "         + F.logsigmoid(torch.sum(emb3(torch.tensor([1])) * emb3(torch.tensor([2])), dim=1))).mean()\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767ee62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dot product between w1 and w2\", torch.sum(emb3.weight[1] * emb3.weight[2]))\n",
    "print(\"Dot product between w0 and w2\", torch.sum(emb3.weight[0] * emb3.weight[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f480c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "man = torch.tensor([1, 0, 0], dtype=float)\n",
    "woman = torch.tensor([-1, 0, 0], dtype=float)\n",
    "royalty = torch.tensor([0, 0, 1], dtype=float)\n",
    "\n",
    "king = torch.tensor([1, 0, 1], dtype=float)\n",
    "queen = torch.tensor([-1, 0, 1], dtype=float)\n",
    "\n",
    "# On a [masculin, féminin, royauté]\n",
    "print(\"homme = king - royalty\")\n",
    "print(\"king - royalty : \", king - royalty)\n",
    "\n",
    "# 3 dimensions qui permet d'encoder 5 mots, chaque dimensions est en quelque sorte un \"sens/concept\"\n",
    "\n",
    "# Deux mots qui partage un sens et pas de différence :\n",
    "print(\"homme * king : \", man.dot(king).numpy())\n",
    "print(\"king * homme : \", king.dot(man).numpy())\n",
    "\n",
    "# Deux mots qui sont différents :\n",
    "print(\"homme * femme\", man.dot(woman).numpy())\n",
    "print(\"homme * queen\", man.dot(queen).numpy())\n",
    "\n",
    "# Deux mots qui n'ont rien en commun (orthogonal)\n",
    "print(\"homme * royalty\", man.dot(royalty).numpy())\n",
    "\n",
    "\n",
    "visualize_normalized_gradients(\n",
    "    embeddings=np.array([[1, 0, 0],\n",
    "                        [-1, 0, 0],\n",
    "                        [0, 0, 1],\n",
    "                        [1, 0, 1],\n",
    "                        [-1, 0, 1]]),\n",
    "    labels=[\"man\", \"woman\", \"royalty\", \"king\", \"queen\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5fd0c5",
   "metadata": {},
   "source": [
    "$$\n",
    "J = - \\log \\sigma(\\mathbf{u}_c \\cdot \\mathbf{v}_w) - \\sum_{i=1}^{k} \\log \\sigma(- \\mathbf{u}_{n_i} \\cdot \\mathbf{v}_w)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c9f41e",
   "metadata": {},
   "source": [
    "$$\n",
    "- \\log \\sigma(\\mathbf{u}_c \\cdot \\mathbf{v}_w)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9678e86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-log(sin(homme * king))\", F.logsigmoid(man.dot(king)))\n",
    "print(\"-log(sin(homme * king))\", F.logsigmoid(man.dot(king)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcff5d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On remarque :\n",
    "print(\"-log(sin(homme * homme))\", F.logsigmoid(man.dot(man)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042459ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "man2 = torch.tensor([100, 0, 0], dtype=float)\n",
    "woman2 = torch.tensor([10, 100, 0], dtype=float)\n",
    "royalty2 = torch.tensor([0, 0, 100], dtype=float)\n",
    "\n",
    "king2 = torch.tensor([100, 0, 100], dtype=float)\n",
    "queen2 = torch.tensor([0, 100, 100], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa34100",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-log(sin(king * homme))\", -F.logsigmoid(man.dot(woman)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc628684",
   "metadata": {},
   "source": [
    "![image.png](formuleSG.png)\n",
    "\n",
    "La formule de base du SG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cdb17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(queen @ man)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f069bc",
   "metadata": {},
   "source": [
    "![image.png](cosinSim.png)\n",
    "\n",
    "Formule de similarité\n",
    "(Avec un epsilon pour éviter la division par 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791ca1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"la similarité entre homme et homme\", nn.functional.cosine_similarity(man.unsqueeze(0), man.unsqueeze(0)))\n",
    "print(\"la similarité entre homme et roi \", nn.functional.cosine_similarity(man.unsqueeze(0), king.unsqueeze(0)))\n",
    "print(\"la similarité entre homme et femme \", nn.functional.cosine_similarity(man.unsqueeze(0), woman.unsqueeze(0)))\n",
    "print(\"la loss entre homme et homme\", F.logsigmoid(man.dot(man)))\n",
    "print(\"la loss entre homme et roi\", F.logsigmoid(man.dot(king)))\n",
    "print(\"la loss entre homme et femme (similaire) \", F.logsigmoid(man.dot(woman)))\n",
    "print(\"la loss entre homme et femme (dissimilaire)\", F.logsigmoid(woman.dot(-man)))\n",
    "\n",
    "\n",
    "print(\"\\nValeur plus grandes\")\n",
    "print(\"la similarité entre man et man\", nn.functional.cosine_similarity(man2.unsqueeze(0), man2.unsqueeze(0)))\n",
    "print(\"la similarité entre man et roi \", nn.functional.cosine_similarity(man2.unsqueeze(0), king2.unsqueeze(0)))\n",
    "print(\"la loss entre homme et homme\", F.logsigmoid(man2.dot(man2)))\n",
    "print(\"la loss entre homme et roi\", F.logsigmoid(man2.dot(king2)))\n",
    "print(\"la loss entre homme et femme (pos) \", F.logsigmoid(man2.dot(woman2)))\n",
    "print(\"la loss entre homme et femme (négatif)\", F.logsigmoid((-man2).dot(woman2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6dd598",
   "metadata": {},
   "source": [
    "On remarque que la fonction de loss n'est pas égal à la similarité. La loss à pour objectifs d'être le plus \"simple\" pour pouvoir process les mots le plus rapidement possible.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3ab6e9",
   "metadata": {},
   "source": [
    "# Init embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d47d441",
   "metadata": {},
   "outputs": [],
   "source": [
    "man3 = torch.tensor([1, 0, 0], dtype=float, requires_grad=True)\n",
    "woman3 = torch.tensor([1, 1, 0], dtype=float, requires_grad=True)\n",
    "king3 = torch.tensor([1, 0, 1], dtype=float, requires_grad=True)\n",
    "\n",
    "encoder = {\n",
    "    \"man\": 0,\n",
    "    \"woman\": 1,\n",
    "    \"king\": 2,\n",
    "}\n",
    "base_color = {}\n",
    "\n",
    "emb = nn.Embedding(3, 3)\n",
    "\n",
    "with torch.no_grad():\n",
    "    emb.weight[0] = man3\n",
    "    emb.weight[1] = woman3\n",
    "    emb.weight[2] = king3\n",
    "init_emb = deepcopy(emb.weight.detach().numpy())\n",
    "\n",
    "fig = components_to_fig_3D(\n",
    "    components=deepcopy(emb.weight.detach().numpy()),\n",
    "    encoder=encoder,\n",
    "    highlight_words=[\"man\", \"woman\", \"king\"],\n",
    "    nb_neighbors=0,\n",
    "    base_color=base_color\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec228e1",
   "metadata": {},
   "source": [
    "# Compute loss and see gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6d2436",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = -(\n",
    "    F.logsigmoid(emb.weight[0].dot(emb.weight[2]))\n",
    "    + F.logsigmoid(-emb.weight[0].dot(emb.weight[1]))\n",
    ").mean()\n",
    "print(\"loss for man similar to king and dissimilar to woman\", loss)\n",
    "loss.backward(retain_graph=None)\n",
    "\n",
    "print(emb.weight.grad.clone())\n",
    "\n",
    "print(\n",
    "    \"Cosine similarity man and woman \",\n",
    "    nn.functional.cosine_similarity(man3.unsqueeze(0), woman3.unsqueeze(0)),\n",
    ")\n",
    "print(\n",
    "    \"Cosine similarity man and king\",\n",
    "    nn.functional.cosine_similarity(man3.unsqueeze(0), king.unsqueeze(0)),\n",
    ")\n",
    "print(\n",
    "    \"Cosine similarity woman and king\",\n",
    "    nn.functional.cosine_similarity(woman3.unsqueeze(0), king3.unsqueeze(0)),\n",
    ")\n",
    "\n",
    "gradient = -emb.weight.grad.detach().numpy()\n",
    "visualize_normalized_gradients(\n",
    "    emb.weight.detach().numpy(), gradients=gradient, labels=labels, visual_length=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ff845a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embAdam = deepcopy(emb)\n",
    "embSGD = deepcopy(emb)\n",
    "\n",
    "embAdam.weight.grad = emb.weight.grad\n",
    "embSGD.weight.grad = emb.weight.grad\n",
    "\n",
    "\n",
    "# loss = -(F.logsigmoid(emb.weight[0].dot(emb.weight[2])) + F.logsigmoid(-emb.weight[0].dot(emb.weight[1]))).mean()\n",
    "\n",
    "opti = torch.optim.SGD(embSGD.parameters(), lr=1.6)\n",
    "opti.step()\n",
    "\n",
    "\n",
    "opti = torch.optim.Adam(embAdam.parameters(), lr=1)\n",
    "opti.step()\n",
    "\n",
    "visualize_normalized_gradients(\n",
    "    embeddings=init_emb,\n",
    "    embeddings_after=[embSGD.weight.detach().numpy(), embAdam.weight.detach().numpy()],\n",
    "    gradients=gradient,\n",
    "    labels=labels,\n",
    "    labels_after=[\"SGD\", \"ADAM\"],\n",
    "    visual_length=0.2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9655586e",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb.weight.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335218b4",
   "metadata": {},
   "source": [
    "# Initialisation et raffinage\n",
    "On va essayer de placer intelligemment un nouveau mots (Queen) avec des mots déjà placer : Man, Woman, King, royalty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5b477b",
   "metadata": {},
   "source": [
    "## Premise, avoir des vecteurs stables ?\n",
    "Première question est quels vecteurs sont stables par rapport a la loss et l'optimiser ?  \n",
    "- Pour savoir si nos vecteurs sont stable, il faut définir un objectif.  \n",
    "L'objectif que je propose est donc d'avoir les pairs similaire suivante : King et homme | roi et royalty  \n",
    "Les paires différentes suivante : homme et femme | roi et femme  \n",
    "Et les pairs sans rapport homme et royalty | femme et roi\n",
    "\n",
    "Deuxième question (on peut l'ignorer pour l'instant si c'est gênant) est ce que le modèle peut avoir des dimensions non utilisé ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9c7ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "facteur = 0.1\n",
    "\n",
    "man = torch.tensor([5, 0, -1], dtype=float, requires_grad=True) * facteur\n",
    "woman = torch.tensor([-5, 0, -1], dtype=float, requires_grad=True) * facteur\n",
    "king = torch.tensor([5, 5, 1], dtype=float, requires_grad=True) * facteur\n",
    "royalty = torch.tensor([1, 5, -5], dtype=float, requires_grad=True) * facteur\n",
    "\n",
    "encoder = {\n",
    "    \"man\": 0,\n",
    "    \"woman\": 1,\n",
    "    \"king\": 2,\n",
    "    \"royalty\": 3,\n",
    "    \"queen\": 4,\n",
    "    \"queen2\": 5\n",
    "}\n",
    "\n",
    "emb = nn.Embedding(10, 3)\n",
    "\n",
    "labels = list(encoder.keys())\n",
    "\n",
    "with torch.no_grad():\n",
    "    emb.weight[0] = man\n",
    "    emb.weight[1] = woman\n",
    "    emb.weight[2] = king\n",
    "    emb.weight[3] = royalty\n",
    "    \n",
    "init_emb = deepcopy(emb.weight.detach().numpy())\n",
    "\n",
    "# On vérifie la stabilité \n",
    "print(\"Similar pair :\")\n",
    "print(f\"Loss for man and king : {F.logsigmoid(emb.weight[encoder[\"man\"]].dot(emb.weight[encoder[\"king\"]]))} (dot product {emb.weight[encoder[\"man\"]].dot(emb.weight[encoder[\"king\"]])})\")\n",
    "print(f\"Loss for king and royalty : {F.logsigmoid(emb.weight[encoder[\"king\"]].dot(emb.weight[encoder[\"royalty\"]]))} (dot product {emb.weight[encoder[\"king\"]].dot(emb.weight[encoder[\"royalty\"]])})\")\n",
    "print(\"Dissimilar Pair -v * u\")\n",
    "print(f\"Loss for man and woman : {F.logsigmoid(emb.weight[encoder[\"woman\"]].dot(-emb.weight[encoder[\"man\"]]))} (dot product {emb.weight[encoder[\"woman\"]].dot(-emb.weight[encoder[\"man\"]])})\")\n",
    "print(f\"Loss for king and woman : {F.logsigmoid(emb.weight[encoder[\"woman\"]].dot(-emb.weight[encoder[\"king\"]]))} (dot product {emb.weight[encoder[\"woman\"]].dot(-emb.weight[encoder[\"king\"]])})\")\n",
    "print(f\"Neutral pair objectif no loss but dot product :\")\n",
    "print(f\"Loss for man and royalty : dot product {emb.weight[encoder[\"man\"]].dot(-emb.weight[encoder[\"royalty\"]])})\")\n",
    "print(f\"Loss for woman and royalty : dot product {emb.weight[encoder[\"woman\"]].dot(-emb.weight[encoder[\"royalty\"]])})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d83f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels)\n",
    "visualize_normalized_gradients(\n",
    "    emb.weight.detach().numpy(),\n",
    "    labels=labels, gradients=None, \n",
    "    embeddings_after=[],\n",
    "    labels_after= ['SGD', 'ADAM'],\n",
    "    word_to_display=labels,\n",
    "    visual_length=2.6\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ce474a",
   "metadata": {},
   "source": [
    "## Première idée\n",
    "Le but est de voir comment, après un placement bouger un nouveaux mot de manière correcte.  \n",
    "Premier scénario, on ajoute queen :  \n",
    "On met queen proche de woman. Puis on rend se mots similaire de royalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6120921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "queen = torch.tensor([-2, 0, -0.4], dtype=float, requires_grad=True) * facteur\n",
    "queen2 = torch.tensor([-5, 0, -1], dtype=float, requires_grad=True) * facteur\n",
    "\n",
    "with torch.no_grad():\n",
    "    emb.weight[encoder[\"queen\"]] = queen\n",
    "    emb.weight[encoder[\"queen2\"]] = queen2\n",
    "\n",
    "loss = -(F.logsigmoid(emb.weight[encoder['queen']].dot(emb.weight[encoder[\"royalty\"]])))\n",
    "\n",
    "print(loss)\n",
    "loss.backward(retain_graph=None)\n",
    "grad1 = emb.weight.grad.clone().numpy()\n",
    "\n",
    "emb_SGD = deepcopy(emb)\n",
    "emb_SGD.weight.grad = deepcopy(emb.weight.grad)\n",
    "\n",
    "emb_ADAM = deepcopy(emb)\n",
    "emb_ADAM.weight.grad = deepcopy(emb.weight.grad)\n",
    "\n",
    "opti_SGD = torch.optim.SGD(emb_SGD.parameters(), lr=1)\n",
    "opti_SGD.step()\n",
    "\n",
    "visualize_normalized_gradients(\n",
    "    emb.weight.detach().numpy(),\n",
    "    labels=labels, gradients=-grad1, \n",
    "    embeddings_after=[emb_SGD.weight.detach().numpy(), emb_ADAM.weight.detach().numpy()],\n",
    "    labels_after= ['SGD', 'ADAM'],\n",
    "    word_to_display=labels,\n",
    "    visual_length=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515ce6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_SGD = -(F.logsigmoid(emb_SGD.weight[encoder['queen']].dot(emb_SGD.weight[encoder[\"royalty\"]])))\n",
    "loss_ADAM = -(F.logsigmoid(emb_ADAM.weight[encoder['queen']].dot(emb_ADAM.weight[encoder[\"royalty\"]])))\n",
    "\n",
    "emb_SGD1 = deepcopy(emb_SGD)\n",
    "emb_ADAM1 = deepcopy(emb_ADAM)\n",
    "\n",
    "loss_SGD.backward(retain_graph=None)\n",
    "grad_SGD = emb_SGD.weight.grad.clone().numpy()\n",
    "loss_ADAM.backward(retain_graph=None)\n",
    "grad_ADAM = emb_ADAM.weight.grad.clone().numpy()\n",
    "\n",
    "opti_SGD.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef410f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_normalized_gradients(\n",
    "    emb_SGD1.weight.detach().numpy(),\n",
    "    labels=labels, gradients=-grad_SGD, \n",
    "    embeddings_after=[emb_SGD.weight.detach().numpy()], \n",
    "    labels_after= ['SGD'], word_to_display=[\"queen\", \"royalty\", \"woman\"],\n",
    "    visual_length=2.6\n",
    ")\n",
    "\n",
    "visualize_normalized_gradients(\n",
    "    emb_ADAM1.weight.detach().numpy(),\n",
    "    labels=labels, gradients=-grad_ADAM, \n",
    "    embeddings_after=[emb_ADAM.weight.detach().numpy()], \n",
    "    labels_after= ['ADAM'],\n",
    "    visual_length=2.6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba1e59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Similar pair :\")\n",
    "print(f\"Loss for man and king : {F.logsigmoid(emb_SGD.weight[encoder[\"man\"]].dot(emb_SGD.weight[encoder[\"king\"]]))} (dot product {emb_SGD.weight[encoder[\"man\"]].dot(emb_SGD.weight[encoder[\"king\"]])})\")\n",
    "print(f\"Loss for king and royalty : {F.logsigmoid(emb_SGD.weight[encoder[\"king\"]].dot(emb_SGD.weight[encoder[\"royalty\"]]))} (dot product {emb_SGD.weight[encoder[\"king\"]].dot(emb_SGD.weight[encoder[\"royalty\"]])})\")\n",
    "print(\"Dissimilar Pair -v * u\")\n",
    "print(f\"Loss for man and woman : {F.logsigmoid(emb_SGD.weight[encoder[\"woman\"]].dot(-emb_SGD.weight[encoder[\"man\"]]))} (dot product {emb_SGD.weight[encoder[\"woman\"]].dot(-emb_SGD.weight[encoder[\"man\"]])})\")\n",
    "print(f\"Loss for king and woman : {F.logsigmoid(emb_SGD.weight[encoder[\"woman\"]].dot(-emb_SGD.weight[encoder[\"king\"]]))} (dot product {emb_SGD.weight[encoder[\"woman\"]].dot(-emb_SGD.weight[encoder[\"king\"]])})\")\n",
    "print(f\"Neutral pair objectif no loss but dot product :\")\n",
    "print(f\"Loss for man and royalty : dot product {emb_SGD.weight[encoder[\"man\"]].dot(-emb_SGD.weight[encoder[\"royalty\"]])})\")\n",
    "print(f\"Loss for woman and royalty : dot product {emb_SGD.weight[encoder[\"woman\"]].dot(-emb_SGD.weight[encoder[\"royalty\"]])})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa3b99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loss for queen and king (Dissimilar) : {F.logsigmoid(-emb_SGD.weight[encoder[\"queen\"]].dot(emb_SGD.weight[encoder[\"king\"]]))} (dot product {emb_SGD.weight[-encoder[\"queen\"]].dot(emb_SGD.weight[encoder[\"king\"]])})\")\n",
    "print(f\"Loss for queen and woman (similar) : {F.logsigmoid(emb_SGD.weight[encoder[\"queen\"]].dot(emb_SGD.weight[encoder[\"woman\"]]))} (dot product {emb_SGD.weight[encoder[\"queen\"]].dot(emb_SGD.weight[encoder[\"woman\"]])})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f6d843",
   "metadata": {},
   "source": [
    "# How use intonation in embedding ? \n",
    "The main idea is that the caregiver emphasizes the words that are important to “understand.” Word 2 Vec is based on the ability to look at lots of words in order to find the best vector space. With a very large corpus, it is possible to identify words that have a “deep” meaning using different statistical techniques. And we hope that this also affects W2V. But children don't need a lot of data to acquire language.\n",
    "So there is (maybe) a way to know which words we should create a deep meaning for and guess which ones are only useful for syntax. Et je suppose que les intonations dans la voix peuvent aider a créer plus rapidement un espace intéressant. En boostant la réctification d'erreur sur les mots qui sont important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c434aab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [\n",
    "    (\"veryImportantWord\", \"stopWord\", [\"veryImportantWord2\"], 1.9),\n",
    "    (\"veryImportantWord2\", \"stopWord\", [\"veryImportantWord\"], 1.9),\n",
    "    (\"stopWord\", \"stopWord2\", [\"veryImportantWord\"], 0.1),\n",
    "    (\"veryImportantWord\", \"adjectifNiceToDefineOtherWord\", [\"veryImportantWord2\"], 1),\n",
    "    (\"veryImportantWord2\", \"adjectifNiceToDefineOtherWord2\", [\"veryImportantWord2\"], 1),\n",
    "    (\"adjectifNiceToDefineOtherWord\", \"stopWord\", [\"veryImportantWord\"], 1),\n",
    "    (\"adjectifNiceToDefineOtherWord\", \"stopWord2\", [\"veryImportantWord2\"], 1),\n",
    "    (\"veryImportantWord\", \"stopWord\", [\"veryImportantWord2\"], 1.9),\n",
    "    (\"adjectifNiceToDefineOtherWord\", \"stopWord2\", [\"veryImportantWord\"], 1),\n",
    "    (\"veryImportantWord2\", \"stopWord2\", [\"veryImportantWord2\"], 1.9),\n",
    "    (\"adjectifNiceToDefineOtherWord\", \"stopWord\", [\"veryImportantWord2\"], 1),\n",
    "    (\"veryImportantWord2\", \"stopWord\", [\"veryImportantWord\"], 1.9),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b176f3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(6, 3)\n",
    "word_to_idx = {\n",
    "    \"veryImportantWord\": 0,\n",
    "    \"stopWord\": 1,\n",
    "    \"stopWord2\": 2,\n",
    "    \"adjectifNiceToDefineOtherWord\": 3,\n",
    "    \"adjectifNiceToDefineOtherWord2\": 4,\n",
    "    \"veryImportantWord2\": 5,\n",
    "}\n",
    "with torch.no_grad():\n",
    "    embedding.weight[0] = torch.tensor([1, 0, 0], dtype=float, requires_grad=True)\n",
    "    embedding.weight[1] = torch.tensor([0, 1, 0], dtype=float, requires_grad=True)\n",
    "    embedding.weight[2] = torch.tensor([0, 0, 1], dtype=float, requires_grad=True)\n",
    "    embedding.weight[3] = torch.tensor([-1, 0, 0], dtype=float, requires_grad=True)\n",
    "    embedding.weight[4] = torch.tensor([0, -1, 0], dtype=float, requires_grad=True)\n",
    "    embedding.weight[5] = torch.tensor([0, 0, -1], dtype=float, requires_grad=True)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     random_weights = torch.randn(6, 3)\n",
    "#     normalized_weights = F.normalize(random_weights, p=2, dim=1)\n",
    "#     embedding.weight.data.copy_(normalized_weights)\n",
    "    \n",
    "    \n",
    "optimizer = optim.SGD(embedding.parameters(), lr=0.1)\n",
    "\n",
    "all_emb = [deepcopy(embedding.weight.detach().numpy())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79084d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_normalized_gradients(\n",
    "    embeddings=all_emb[0], \n",
    "    embeddings_after=[],\n",
    "    labels=list(word_to_idx.keys()),\n",
    "    word_to_display=None,\n",
    "    gradients=None, labels_after=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f852cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.zero_grad()\n",
    "\n",
    "wordTarget, wordContext, listOfNeg, weight = pairs[0]\n",
    "wordTarget = embedding.weight[word_to_idx[wordTarget]]\n",
    "wordContext = embedding.weight[word_to_idx[wordContext]]\n",
    "listOfNeg = embedding(torch.tensor([word_to_idx[word_con] for word_con in listOfNeg]))\n",
    "\n",
    "print(f\"Word target {wordTarget}\")\n",
    "print(f\"word context {wordContext}\")\n",
    "print(f\"list of neg {listOfNeg}\")\n",
    "print(f\"Weight {weight}\")\n",
    "\n",
    "pos_score = F.logsigmoid(wordTarget.dot(wordContext))\n",
    "neg_score = -F.logsigmoid(listOfNeg @ wordTarget)\n",
    "\n",
    "print(f\"pos score : {pos_score}\")\n",
    "print(f\"neg score : {neg_score}\")\n",
    "\n",
    "loss = -((pos_score + neg_score)).mean()\n",
    "# loss = -((pos_score + neg_score)).mean() * weight\n",
    "\n",
    "print(f\"loss : {loss}\")\n",
    "loss.backward()\n",
    "print(f\"grad : {embedding.weight.grad}\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92ada32",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.zero_grad()\n",
    "\n",
    "wordTarget, wordContext, listOfNeg, weight = pairs[0]\n",
    "wordTargetTensor = embedding.weight[word_to_idx[wordTarget]]\n",
    "wordContextTensor = embedding.weight[word_to_idx[wordContext]]\n",
    "listOfNegTensor = embedding(torch.tensor([word_to_idx[word_con] for word_con in listOfNeg]))\n",
    "\n",
    "print(f\"Word target {wordTargetTensor}\")\n",
    "print(f\"word context {wordContextTensor}\")\n",
    "print(f\"list of neg {listOfNegTensor}\")\n",
    "print(f\"Weight {weight}\")\n",
    "\n",
    "pos_score = F.logsigmoid(wordTargetTensor.dot(wordContextTensor))\n",
    "neg_score = -F.logsigmoid(listOfNegTensor @ wordTargetTensor)\n",
    "\n",
    "print(f\"pos score : {pos_score}\")\n",
    "print(f\"neg score : {neg_score}\")\n",
    "\n",
    "loss = -((pos_score + neg_score)).mean()\n",
    "# loss = -((pos_score + neg_score)).mean() * weight\n",
    "\n",
    "print(f\"loss : {loss}\")\n",
    "loss.backward()\n",
    "print(f\"grad : {embedding.weight.grad}\")\n",
    "embedding.weight.grad[word_to_idx[wordTarget]] *= weight\n",
    "\n",
    "print(f\"grad : {embedding.weight.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029b2ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnlyOneEmbWeighted(nn.Module):\n",
    "    def __init__(self, emb_size:int, embedding_dimension:int=15, \n",
    "                init_range:float|None=None, sparse:bool=True, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.emb_size:int = emb_size\n",
    "        self.emb_dim:int = embedding_dimension\n",
    "        self.word_emb:nn.Embedding = nn.Embedding(num_embeddings=self.emb_size, \n",
    "                                                embedding_dim=self.emb_dim, device=device, sparse=sparse)\n",
    "\n",
    "        if init_range is None:\n",
    "            init_range = 0.5 / self.emb_dim\n",
    "        self.word_emb.weight.data.uniform_(-init_range, init_range)\n",
    "\n",
    "    def forward(self, centrals_words:torch.Tensor, pos_context:torch.Tensor,\n",
    "                neg_context:torch.Tensor, weights:torch.Tensor):\n",
    "        words_emb:torch.Tensor = self.word_emb(centrals_words) # [B, D]\n",
    "        context_emb:torch.Tensor = self.word_emb(pos_context) # [B, D]\n",
    "        neg_emb:torch.Tensor = self.word_emb(neg_context) # [B, K, D]\n",
    "        \n",
    "        weights = weights.view(-1, 1)\n",
    "        \n",
    "        def weight_hook(grad):\n",
    "            return grad * weights\n",
    "            \n",
    "        words_emb.register_hook(weight_hook)\n",
    "\n",
    "        pos_score = torch.sum(words_emb * context_emb, dim=1)\n",
    "        pos_loss = F.logsigmoid(pos_score)\n",
    "\n",
    "        neg_score = torch.bmm(neg_emb, words_emb.unsqueeze(-1)).squeeze(2)\n",
    "        neg_loss = F.logsigmoid(-neg_score).sum(1)\n",
    "\n",
    "        loss = -(pos_loss + neg_loss).mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8facbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = OnlyOneEmb(emb_size=len(word_to_idx.keys()), embedding_dimension=3)\n",
    "optimizer = optim.SGD(model_test.parameters(), lr=0.1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model_test.word_emb.weight[0] = torch.tensor([1, 0, 0], dtype=float, requires_grad=True)\n",
    "    model_test.word_emb.weight[1] = torch.tensor([0, 1, 0], dtype=float, requires_grad=True)\n",
    "    model_test.word_emb.weight[2] = torch.tensor([0, 0, 1], dtype=float, requires_grad=True)\n",
    "    model_test.word_emb.weight[3] = torch.tensor([-1, 0, 0], dtype=float, requires_grad=True)\n",
    "    model_test.word_emb.weight[4] = torch.tensor([0, -1, 0], dtype=float, requires_grad=True)\n",
    "    model_test.word_emb.weight[5] = torch.tensor([0, 0, -1], dtype=float, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00cd21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_test.word_emb(torch.tensor([0, 1,2,3])).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe8b35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation of batch\n",
    "wordTargetIdx = []\n",
    "wordContextIdx = []\n",
    "listOfNegTensor = []\n",
    "weightsTensor = []\n",
    "\n",
    "for wT, wC, wN, wW in pairs:\n",
    "    wordTargetIdx.append(word_to_idx[wT])\n",
    "    wordContextIdx.append(word_to_idx[wC])\n",
    "    listOfNegTensor.append([word_to_idx[word_con] for word_con in wN])\n",
    "    weightsTensor.append(wW)\n",
    "\n",
    "batchWordTarget = torch.tensor(wordTargetIdx)\n",
    "batchWordContext = torch.tensor(wordContextIdx)\n",
    "batchWordNeg = torch.tensor(listOfNegTensor)\n",
    "batchWeights = torch.tensor(weightsTensor)\n",
    "\n",
    "\n",
    "# print(f\"Word target {batchWordTarget}, {model_test.word_emb(batchWordTarget)}\")\n",
    "# print(f\"word context {batchWordContext}\")\n",
    "# print(f\"list of neg {batchWordNeg.size()}\")\n",
    "# print(f\"Weight {batchWeights}\")\n",
    "\n",
    "optimizer.zero_grad()\n",
    "loss = model_test(batchWordTarget, batchWordContext, batchWordNeg, batchWeights)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5f086d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78d3723",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test.word_emb.zero_grad()\n",
    "for wordTarget, wordContext, listOfNeg, weights in pairs :\n",
    "    wordTargetIdx = torch.tensor([word_to_idx[wordTarget]])\n",
    "    wordContextIdx = torch.tensor([word_to_idx[wordContext]])\n",
    "    listOfNegTensor = torch.tensor([[word_to_idx[word_con] for word_con in listOfNeg]])\n",
    "    weightsTensor = torch.tensor([weights])\n",
    "    \n",
    "    print(f\"Word target {wordTargetIdx}, {model_test.word_emb(wordTargetIdx)}\")\n",
    "    print(f\"word context {wordContextIdx}\")\n",
    "    print(f\"list of neg {listOfNegTensor}\")\n",
    "    print(f\"Weight {weightsTensor}\")\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss = model_test(wordTargetIdx, wordContextIdx, listOfNegTensor, weightsTensor)\n",
    "    loss.backward()\n",
    "    break\n",
    "    \n",
    "    # loss.backward()\n",
    "\t# optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
