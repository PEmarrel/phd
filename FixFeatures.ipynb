{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131a8d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import random\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from visuEmbedding import interactive_embedding_plot_3D, components_to_fig_3D, components_to_fig_3D_animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8b7864",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixeFeatureSkipGramModel(nn.Module):\n",
    "    def __init__(self, emb_size:int, embedding_dimension:int=15, init_range:float|None=None, sparse:bool=True, device=\"cpu\"):\n",
    "        \"\"\"Init out model\n",
    "        Args:\n",
    "            emb_size: This is the number of words that our embedding will contain. \n",
    "            embedding_dimension: Number of dimension which will represent our words\n",
    "        \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.emb_size:int = emb_size\n",
    "        self.emb_dim:int = embedding_dimension\n",
    "        self.con_size:int = embedding_dimension # Not our goal to modifie this parameter\n",
    "        self.word_emb:nn.Embedding = nn.Embedding(num_embeddings=self.emb_size, embedding_dim=self.emb_dim, device=device, sparse=sparse)\n",
    "        self.con_emb:nn.Embedding = nn.Embedding(num_embeddings=self.emb_size, embedding_dim=self.con_size, device=device,sparse=sparse)\n",
    "\n",
    "        if init_range is None:\n",
    "            init_range = 0.5 / self.emb_dim\n",
    "        self.word_emb.weight.data.uniform_(-init_range, init_range)\n",
    "        self.con_emb.weight.data.uniform_(-init_range, init_range)\n",
    "\n",
    "    def forward(self, centrals_words:list[int]|torch.Tensor, pos_context:list|torch.Tensor, neg_context:list|torch.Tensor):\n",
    "        \"\"\"Forward for SkipGramModel (To modify in futur)\n",
    "        For now based in SNSG\n",
    "        Args:\n",
    "            centrals_words: Index of central word\n",
    "            pos_context: Index of similar words to the central words\n",
    "            neg_context: Index of negative words to the central words. There is an additional dimension because there may be several negative words.\n",
    "        \"\"\"\n",
    "        words_emb:torch.Tensor = self.word_emb(centrals_words) # [B, D]\n",
    "        context_emb:torch.Tensor = self.con_emb(pos_context) # [B, D]\n",
    "        neg_emb:torch.Tensor = self.con_emb(neg_context) # [B, K, D]\n",
    "\n",
    "        pos_score = torch.sum(words_emb * context_emb, dim=1)\n",
    "        pos_loss = F.logsigmoid(pos_score)\n",
    "        neg_score = torch.bmm(neg_emb, words_emb.unsqueeze(-1)).squeeze(2)\n",
    "        neg_loss = F.logsigmoid(-neg_score).sum(1)\n",
    "\n",
    "        loss = - (pos_loss + neg_loss).mean()\n",
    "        return loss\n",
    "    \n",
    "    def save_weight(self, path:str=\"SGNS_weights/\"):\n",
    "        \"\"\"Save weight with name word_embedding.pt and con_embedding.pt\n",
    "        Args :\n",
    "            path: Folder to save.\n",
    "        \"\"\"\n",
    "        word_weights = self.word_emb.weight.detach().cpu()\n",
    "        con_weight = self.con_emb.weight.detach().cpu()\n",
    "        torch.save(word_weights, path+'word_embedding.pt')\n",
    "        torch.save(con_weight, path+'con_embedding.pt')\n",
    "\n",
    "    def load_weight(self, path:str=\"SGNS_weights/\", name_word_weights:str=\"word_embedding.pt\", name_con_weights:str=\"con_embedding.pt\"):\n",
    "        \"\"\"Load weights\n",
    "        Args :\n",
    "            path: Folder where are weights files\n",
    "            name_word_weights: Name for central words\n",
    "            name_con_weights: Name for context words\n",
    "        \"\"\"\n",
    "        word_weights = torch.load(path + name_word_weights)\n",
    "        con_weight = torch.load(path + name_con_weights)\n",
    "\n",
    "        self.word_emb:nn.Embedding = nn.Embedding.from_pretrained(word_weights)\n",
    "        self.con_emb:nn.Embedding = nn.Embedding.from_pretrained(con_weight)\n",
    "        \n",
    "    def __increase_embeddings(self, new_word_w:torch.Tensor, new_con_w:torch.Tensor):\n",
    "        with torch.no_grad():\n",
    "            updated_word_w = torch.cat([self.word_emb.weight.data, new_word_w.unsqueeze(0)], dim=0)\n",
    "            updated_con_w = torch.cat([self.con_emb.weight.data, new_con_w.unsqueeze(0)], dim=0)\n",
    "\n",
    "        self.word_emb = nn.Embedding.from_pretrained(updated_word_w, freeze=False, sparse=self.word_emb.sparse)\n",
    "        self.con_emb = nn.Embedding.from_pretrained(updated_con_w, freeze=False, sparse=self.con_emb.sparse)\n",
    "        self.emb_size+=1\n",
    "        \n",
    "    def extend_vocabulary(self, ref_central_vector: torch.Tensor, ref_context_vector: torch.Tensor, epsilon: float = 0.05):\n",
    "        \"\"\"\n",
    "        Extends the vocabulary by adding new embeddings initialized close to a reference vector.\n",
    "        \n",
    "        Args:\n",
    "            ref_vector: A tensor of shape (embedding_dimension,) to use as the \"center\".\n",
    "            epsilon: The magnitude of the random noise.\n",
    "        \"\"\"\n",
    "        \n",
    "        noise_word = torch.randn(self.emb_dim) * epsilon\n",
    "        noise_con = torch.randn(self.con_size) * epsilon\n",
    "        \n",
    "        new_word_w = ref_central_vector + noise_word\n",
    "        new_con_w = ref_context_vector + noise_con\n",
    "        \n",
    "        self.__increase_embeddings(new_word_w, new_con_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d146b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixOnlyOneEmb(nn.Module):\n",
    "    def __init__(self, emb_size:int, embedding_dimension:int=15, init_range:float|None=None, sparse:bool=True, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.emb_size:int = emb_size\n",
    "        self.emb_dim:int = embedding_dimension\n",
    "        self.word_emb:nn.Embedding = nn.Embedding(num_embeddings=self.emb_size, embedding_dim=self.emb_dim, device=device, sparse=sparse)\n",
    "\n",
    "        if init_range is None:\n",
    "            init_range = 0.5 / self.emb_dim\n",
    "        self.word_emb.weight.data.uniform_(-init_range, init_range)\n",
    "\n",
    "    def forward(self, centrals_words:list|torch.Tensor, pos_context:list|torch.Tensor, neg_context:list|torch.Tensor):\n",
    "        words_emb:torch.Tensor = self.word_emb(centrals_words)\n",
    "        context_emb:torch.Tensor = self.word_emb(pos_context)\n",
    "        neg_emb:torch.Tensor = self.word_emb(neg_context)\n",
    "\n",
    "        pos_score = torch.sum(words_emb * context_emb, dim=1)\n",
    "        pos_loss = F.logsigmoid(pos_score)\n",
    "\n",
    "        neg_score = torch.bmm(neg_emb, words_emb.unsqueeze(-1)).squeeze(2)\n",
    "        neg_loss = F.logsigmoid(-neg_score).sum(1)\n",
    "\n",
    "        loss = -(pos_loss + neg_loss).mean()\n",
    "        return loss\n",
    "    \n",
    "    def __increase_embeddings(self, new_word_w:torch.Tensor):\n",
    "        with torch.no_grad():\n",
    "            updated_word_w = torch.cat([self.word_emb.weight.data, new_word_w.unsqueeze(0)], dim=0)\n",
    "\n",
    "        self.word_emb = nn.Embedding.from_pretrained(updated_word_w, freeze=False, sparse=self.word_emb.sparse)\n",
    "        self.emb_size+=1\n",
    "        \n",
    "    def extend_vocabulary(self, ref_central_vector: torch.Tensor, epsilon: float = 0.05):       \n",
    "        noise_word = torch.randn(self.emb_dim) * epsilon\n",
    "        new_word_w = ref_central_vector + noise_word\n",
    "        self.__increase_embeddings(new_word_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2f0397",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixOnlyOneEmbPositifPair(nn.Module):\n",
    "    def __init__(self, emb_size:int, embedding_dimension:int=15, init_range:float|None=None, sparse:bool=True, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.emb_size:int = emb_size\n",
    "        self.emb_dim:int = embedding_dimension\n",
    "        self.word_emb:nn.Embedding = nn.Embedding(num_embeddings=self.emb_size, embedding_dim=self.emb_dim, device=device, sparse=sparse)\n",
    "\n",
    "        if init_range is None:\n",
    "            init_range = 0.5 / self.emb_dim\n",
    "        self.word_emb.weight.data.uniform_(-init_range, init_range)\n",
    "\n",
    "    def forward(self, centrals_words:list|torch.Tensor, pos_context:list|torch.Tensor):\n",
    "        words_emb:torch.Tensor = self.word_emb(centrals_words)\n",
    "        context_emb:torch.Tensor = self.word_emb(pos_context)\n",
    "        neg_emb:torch.Tensor = self.word_emb(neg_context)\n",
    "\n",
    "        pos_score = torch.sum(words_emb * context_emb, dim=1)\n",
    "        pos_loss = F.logsigmoid(pos_score)\n",
    "\n",
    "        neg_score = torch.bmm(neg_emb, words_emb.unsqueeze(-1)).squeeze(2)\n",
    "        neg_loss = F.logsigmoid(-neg_score).sum(1)\n",
    "\n",
    "        loss = -(pos_loss + neg_loss).mean()\n",
    "        return loss\n",
    "    \n",
    "    def __increase_embeddings(self, new_word_w:torch.Tensor):\n",
    "        with torch.no_grad():\n",
    "            updated_word_w = torch.cat([self.word_emb.weight.data, new_word_w.unsqueeze(0)], dim=0)\n",
    "\n",
    "        self.word_emb = nn.Embedding.from_pretrained(updated_word_w, freeze=False, sparse=self.word_emb.sparse)\n",
    "        self.emb_size+=1\n",
    "        \n",
    "    def extend_vocabulary(self, ref_central_vector: torch.Tensor, epsilon: float = 0.05):       \n",
    "        noise_word = torch.randn(self.emb_dim) * epsilon\n",
    "        new_word_w = ref_central_vector + noise_word\n",
    "        self.__increase_embeddings(new_word_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1584ebbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_optimizer(optimizer:torch.optim.Optimizer, old_weight:torch.nn.parameter.Parameter, new_weight:torch.nn.parameter.Parameter):\n",
    "    \"\"\"Transfer informations optimizer to a new optimizer (increase by one)\n",
    "    \"\"\"\n",
    "    if old_weight in optimizer.state:\n",
    "        old_state:dict = optimizer.state[old_weight]\n",
    "        new_state = {}\n",
    "        \n",
    "        for key, value in old_state.items():\n",
    "            if isinstance(value, torch.Tensor):\n",
    "                new_shape = (value.shape[0] + 1, value.shape[1])\n",
    "                new_buffer = torch.zeros(new_shape, device=value.device, dtype=value.dtype)\n",
    "                new_buffer[:value.shape[0]] = value\n",
    "                new_state[key] = new_buffer\n",
    "            else:\n",
    "                new_state[key] = value\n",
    "        \n",
    "        optimizer.state[new_weight] = new_state\n",
    "        del optimizer.state[old_weight]\n",
    "\n",
    "    for group in optimizer.param_groups:\n",
    "        if old_weight in group['params']:\n",
    "            index = group['params'].index(old_weight)\n",
    "            group['params'][index] = new_weight\n",
    "            \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077b1965",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_me = FixeFeatureSkipGramModel(2, 3, 1, True)\n",
    "print(remove_me.parameters)\n",
    "optimizer = torch.optim.SparseAdam(remove_me.parameters())\n",
    "\n",
    "old_weight = remove_me.word_emb.weight\n",
    "print(old_weight)\n",
    "print(optimizer.state[old_weight])\n",
    "print(optimizer.state_dict())\n",
    "type(remove_me.word_emb.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d10bd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extend_vocabulary(self, num_new_words: int, optimizer: torch.optim.Optimizer, ref_vector: torch.Tensor, epsilon: float = 0.05):\n",
    "#         \"\"\"\n",
    "#         Extends vocabulary AND updates the optimizer to keep momentum.\n",
    "#         \"\"\"\n",
    "#         device = self.word_emb.weight.device\n",
    "        \n",
    "#         # --- 1. PREPARE NEW WEIGHTS (Same as before) ---\n",
    "#         ref_vector = ref_vector.to(device).view(1, -1)\n",
    "        \n",
    "#         noise_word = torch.randn(num_new_words, self.emb_dim, device=device) * epsilon\n",
    "#         noise_con = torch.randn(num_new_words, self.con_size, device=device) * epsilon\n",
    "\n",
    "#         new_word_part = ref_vector.expand(num_new_words, -1) + noise_word\n",
    "#         new_con_part = ref_vector.expand(num_new_words, -1) + noise_con\n",
    "\n",
    "#         # --- 2. CAPTURE OLD PARAMETERS ---\n",
    "#         # We need references to the old tensor objects to find them in the optimizer\n",
    "#         old_word_param = self.word_emb.weight\n",
    "#         old_con_param = self.con_emb.weight\n",
    "\n",
    "#         # --- 3. UPDATE MODEL (Create new larger embeddings) ---\n",
    "#         with torch.no_grad():\n",
    "#             updated_word_w = torch.cat([old_word_param.data, new_word_part], dim=0)\n",
    "#             updated_con_w = torch.cat([old_con_param.data, new_con_part], dim=0)\n",
    "\n",
    "#         self.word_emb = nn.Embedding.from_pretrained(updated_word_w, freeze=False, sparse=self.word_emb.sparse)\n",
    "#         self.con_emb = nn.Embedding.from_pretrained(updated_con_w, freeze=False, sparse=self.con_emb.sparse)\n",
    "        \n",
    "#         self.emb_size += num_new_words\n",
    "\n",
    "#         # --- 4. UPDATE OPTIMIZER STATE ---\n",
    "#         # We define a helper to handle the nasty internal dictionary surgery\n",
    "#         def patch_optimizer_state(optimizer, old_param, new_param, num_new_rows):\n",
    "#             # 1. Check if the old parameter actually has state (momentum, etc.)\n",
    "#             if old_param in optimizer.state:\n",
    "#                 old_state = optimizer.state[old_param]\n",
    "#                 new_state = {}\n",
    "                \n",
    "#                 # Iterate over buffers (e.g., 'exp_avg', 'exp_avg_sq' in Adam)\n",
    "#                 for key, value in old_state.items():\n",
    "#                     if isinstance(value, torch.Tensor):\n",
    "#                         # Create a new buffer of zeros with the new larger size\n",
    "#                         # We assume the state tensors match the param shape (which they usually do for embeddings)\n",
    "#                         new_shape = (value.shape[0] + num_new_rows, value.shape[1])\n",
    "#                         new_buffer = torch.zeros(new_shape, device=value.device, dtype=value.dtype)\n",
    "                        \n",
    "#                         # Copy the old momentum into the top part\n",
    "#                         new_buffer[:value.shape[0]] = value\n",
    "                        \n",
    "#                         # The bottom part (new words) starts with 0 momentum (fresh start)\n",
    "#                         new_state[key] = new_buffer\n",
    "#                     else:\n",
    "#                         # Copy non-tensor scalars (like 'step') directly\n",
    "#                         new_state[key] = value\n",
    "                \n",
    "#                 # Assign this new state dictionary to the NEW parameter key\n",
    "#                 optimizer.state[new_param] = new_state\n",
    "                \n",
    "#                 # Delete the old parameter from state\n",
    "#                 del optimizer.state[old_param]\n",
    "\n",
    "#             # 2. Update param_groups (The list the optimizer iterates over)\n",
    "#             for group in optimizer.param_groups:\n",
    "#                 # Replace the old param object with the new one in the list\n",
    "#                 if old_param in group['params']:\n",
    "#                     index = group['params'].index(old_param)\n",
    "#                     group['params'][index] = new_param\n",
    "\n",
    "#         # Apply the fix to both embeddings\n",
    "#         patch_optimizer_state(optimizer, old_word_param, self.word_emb.weight, num_new_words)\n",
    "#         patch_optimizer_state(optimizer, old_con_param, self.con_emb.weight, num_new_words)\n",
    "\n",
    "#         print(f\"Vocabulary extended to {self.emb_size}. Optimizer momentum preserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae938a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FixeFeatureSkipGramModel(emb_size=5, embedding_dimension=3, sparse=True)\n",
    "optimizer = torch.optim.SparseAdam(model.parameters(), lr=0.01)\n",
    "\n",
    "print(model.word_emb.weight)\n",
    "\n",
    "with torch.no_grad():    \n",
    "    model.word_emb.weight[0] = torch.tensor([1, 1, 1], dtype=float)\n",
    "    model.con_emb.weight[0] = torch.tensor([1, 1, 1], dtype=float)\n",
    "    \n",
    "print(model.word_emb.weight)\n",
    "\n",
    "\n",
    "ref_central:torch.Tensor = deepcopy(model.word_emb.weight[0].detach())\n",
    "print(ref_central)\n",
    "\n",
    "model.extend_vocabulary(\n",
    "    ref_central_vector=ref_central,\n",
    "    ref_context_vector=ref_central,\n",
    "    epsilon=0.001\n",
    ")\n",
    "\n",
    "print(model.word_emb.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc961ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_Word2Vec(modelW2V:nn.Module, dataLoader:Dataset, optimizer:optim.Optimizer, epochs:int, verbal:bool=True, log_interval=100, device=\"cpu\"):\n",
    "    \"\"\"Fonction d’entraînement pour un modèle Word2Vec\n",
    "    \"\"\"\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_loss = 0.0\n",
    "        batches = 0\n",
    "        loss_history = []\n",
    "        global_step = 0\n",
    "        \n",
    "        modelW2V.train()\n",
    "\n",
    "        for batch in dataLoader:\n",
    "            # centers: [B], pos: [B], negs: [B, K]\n",
    "            centers, pos, negs = batch\n",
    "            centers = centers.to(device)\n",
    "            pos = pos.to(device)\n",
    "            negs = negs.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = modelW2V(centers, pos, negs)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_loss = loss.item()\n",
    "            epoch_loss += batch_loss\n",
    "            loss_history.append(batch_loss)\n",
    "            batches += 1\n",
    "            global_step += 1\n",
    "\n",
    "            if verbal and log_interval and (global_step % log_interval == 0):\n",
    "                print(f\"Epoch {epoch} Step {global_step} AvgLoss {epoch_loss / batches:.6f}\")\n",
    "\n",
    "        avg_epoch_loss = epoch_loss / max(1, batches)\n",
    "        if verbal : print(f\"Epoch {epoch} finished. Avg loss: {avg_epoch_loss:.6f}\")\n",
    "\n",
    "    return {\"loss_history\": loss_history, \"final_epoch_loss\": avg_epoch_loss}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bb4837",
   "metadata": {},
   "source": [
    "# Data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1948a397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix : A, B, C\n",
    "# A = [-1, 1, 0], B = [0, -1, 1], C = [-1, 0, 1]\n",
    "# No fixe : R, S, T, U, V, W, X, Y, Z\n",
    "data1 = ['R', 'A', ['B', 'C', 'B']] \n",
    "data2 = ['S', 'A', ['B', 'C', 'B']]\n",
    "data3 = ['T', 'A', ['B', 'S', 'R']]\n",
    "\n",
    "data4 = ['S', 'R', ['B', 'C', 'T']]\n",
    "\n",
    "# On veut rapprocher A, X, Y, Z avec Z proche de C et loin de X, Y (X, Y proche)\n",
    "\n",
    "encoder = {\n",
    "    'A' : 0,\n",
    "    'B' : 1,\n",
    "    'C' : 2,\n",
    "    'R' : 3,\n",
    "    'S' : 4,\n",
    "    'T' : 5\n",
    "}\n",
    "\n",
    "base_color =  {\n",
    "    'A' : (\"red\", \"gray\"),\n",
    "    'B' : (\"red\", \"gray\"),\n",
    "    'C' : (\"red\", \"gray\"),\n",
    "    'R' : (\"blue\", \"cyan\"),\n",
    "    'S' : (\"green\", \"lightgreen\"),\n",
    "    'T' : (\"magenta\", \"pink\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764a7cbc",
   "metadata": {},
   "source": [
    "# First model with fixe A, B, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfd6ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FixeFeatureSkipGramModel(emb_size=3, embedding_dimension=3, sparse=True)\n",
    "optimizer = torch.optim.SparseAdam(model.parameters(), lr=0.8)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.word_emb.weight[encoder['A']] = torch.tensor([1, 0, 0])\n",
    "    model.word_emb.weight[encoder['B']] = torch.tensor([0, 1, 0])\n",
    "    model.word_emb.weight[encoder['C']] = torch.tensor([0, 0, 1])\n",
    "    model.con_emb.weight[encoder['A']] = torch.tensor([1, 0, 0])\n",
    "    model.con_emb.weight[encoder['B']] = torch.tensor([0, 1, 0])\n",
    "    model.con_emb.weight[encoder['C']] = torch.tensor([0, 0, 1])\n",
    "    \n",
    "print(model.word_emb.weight)\n",
    "\n",
    "model.extend_vocabulary(\n",
    "    ref_central_vector=deepcopy(model.word_emb.weight[0].detach()),\n",
    "    ref_context_vector=deepcopy(model.word_emb.weight[0].detach()),\n",
    "    epsilon=0.01\n",
    ") # Pose X\n",
    "\n",
    "model.extend_vocabulary(\n",
    "    ref_central_vector=deepcopy(model.word_emb.weight[0].detach()),\n",
    "    ref_context_vector=deepcopy(model.word_emb.weight[0].detach()),\n",
    "    epsilon=0.01\n",
    ") # Pose Y\n",
    "\n",
    "model.extend_vocabulary(\n",
    "    ref_central_vector=deepcopy(model.word_emb.weight[0].detach()),\n",
    "    ref_context_vector=deepcopy(model.word_emb.weight[0].detach()),\n",
    "    epsilon=0.01\n",
    ") # Pose Z\n",
    "\n",
    "optimizer = torch.optim.SparseAdam(model.parameters(), lr=0.8)\n",
    "\n",
    "print(model.word_emb.weight)\n",
    "\n",
    "fig = components_to_fig_3D(components=model.word_emb.weight.detach().numpy(), encoder=encoder, highlight_words=[\"A\", \"R\"], nb_neighbors=0)\n",
    "fig.show()\n",
    "\n",
    "for center, pos, negs in [data1, data2, data3, data4]:\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    central_w = torch.tensor(encoder[center], dtype=int).unsqueeze(0)\n",
    "    pos_w = torch.tensor(encoder[pos], dtype=int).unsqueeze(0)\n",
    "    negs_w = torch.tensor([encoder[idx] for idx in negs], dtype=int).unsqueeze(0)\n",
    "\n",
    "    loss = model(central_w, pos_w, negs_w)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311359b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = components_to_fig_3D(components=deepcopy(model.con_emb.weight.detach().numpy()), encoder=encoder, highlight_words=[\"A\", data1[0]], nb_neighbors=0)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68047076",
   "metadata": {},
   "source": [
    "# Second model with fix A, B, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da810a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FixOnlyOneEmb(emb_size=3, embedding_dimension=3, sparse=True)\n",
    "optimizer = torch.optim.SparseAdam(model.parameters(), lr=0.01)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.word_emb.weight[encoder['A']] = torch.tensor([1, 0, 0])\n",
    "    model.word_emb.weight[encoder['B']] = torch.tensor([0, 1, 0])\n",
    "    model.word_emb.weight[encoder['C']] = torch.tensor([0, 0, 1])\n",
    "    \n",
    "print(model.word_emb.weight)\n",
    "\n",
    "\n",
    "\n",
    "# model.extend_vocabulary(\n",
    "#     ref_central_vector=deepcopy(model.word_emb.weight[0].detach()),\n",
    "#     epsilon=0.1\n",
    "# ) # Pose Y\n",
    "\n",
    "# model.extend_vocabulary(\n",
    "#     ref_central_vector=deepcopy(model.word_emb.weight[0].detach()),\n",
    "#     epsilon=0.1\n",
    "# ) # Pose Z\n",
    "\n",
    "\n",
    "hist_emb = []\n",
    "\n",
    "center, pos, negs = data1\n",
    "model.extend_vocabulary(\n",
    "    ref_central_vector=deepcopy(model.word_emb.weight[0].detach()),\n",
    "    epsilon=0.1\n",
    ") # Pose R\n",
    "optimizer = torch.optim.SparseAdam(model.parameters(), lr=0.01)\n",
    "\n",
    "model.train()\n",
    "optimizer.zero_grad()\n",
    "central_w = torch.tensor(encoder[center], dtype=int).unsqueeze(0)\n",
    "pos_w = torch.tensor(encoder[pos], dtype=int).unsqueeze(0)\n",
    "negs_w = torch.tensor([encoder[idx] for idx in negs], dtype=int).unsqueeze(0)\n",
    "\n",
    "loss = model(central_w, pos_w, negs_w)\n",
    "loss.backward()\n",
    "\n",
    "optimizer.step()\n",
    "with torch.no_grad():\n",
    "    model.word_emb.weight[encoder['A']] = torch.tensor([1, 0, 0])\n",
    "    model.word_emb.weight[encoder['B']] = torch.tensor([0, 1, 0])\n",
    "    model.word_emb.weight[encoder['C']] = torch.tensor([0, 0, 1])\n",
    "hist_emb.append(model.word_emb.weight.detach().numpy())\n",
    "\n",
    "\n",
    "\n",
    "center, pos, negs = data2\n",
    "model.extend_vocabulary(\n",
    "    ref_central_vector=deepcopy(model.word_emb.weight[0].detach()),\n",
    "    epsilon=0.1\n",
    ") # Pose S\n",
    "optimizer = torch.optim.SparseAdam(model.parameters(), lr=0.01)\n",
    "\n",
    "model.train()\n",
    "optimizer.zero_grad()\n",
    "central_w = torch.tensor(encoder[center], dtype=int).unsqueeze(0)\n",
    "pos_w = torch.tensor(encoder[pos], dtype=int).unsqueeze(0)\n",
    "negs_w = torch.tensor([encoder[idx] for idx in negs], dtype=int).unsqueeze(0)\n",
    "\n",
    "loss = model(central_w, pos_w, negs_w)\n",
    "loss.backward()\n",
    "\n",
    "optimizer.step()\n",
    "with torch.no_grad():\n",
    "    model.word_emb.weight[encoder['A']] = torch.tensor([1, 0, 0])\n",
    "    model.word_emb.weight[encoder['B']] = torch.tensor([0, 1, 0])\n",
    "    model.word_emb.weight[encoder['C']] = torch.tensor([0, 0, 1])\n",
    "hist_emb.append(model.word_emb.weight.detach().numpy())\n",
    "    \n",
    "    \n",
    "center, pos, negs = data3\n",
    "model.extend_vocabulary(\n",
    "    ref_central_vector=deepcopy(model.word_emb.weight[0].detach()),\n",
    "    epsilon=0.1\n",
    ") # Pose T\n",
    "optimizer = torch.optim.SparseAdam(model.parameters(), lr=0.1)\n",
    "\n",
    "model.train()\n",
    "optimizer.zero_grad()\n",
    "central_w = torch.tensor(encoder[center], dtype=int).unsqueeze(0)\n",
    "pos_w = torch.tensor(encoder[pos], dtype=int).unsqueeze(0)\n",
    "negs_w = torch.tensor([encoder[idx] for idx in negs], dtype=int).unsqueeze(0)\n",
    "\n",
    "loss = model(central_w, pos_w, negs_w)\n",
    "loss.backward()\n",
    "\n",
    "optimizer.step()\n",
    "with torch.no_grad():\n",
    "    model.word_emb.weight[encoder['A']] = torch.tensor([1, 0, 0])\n",
    "    model.word_emb.weight[encoder['B']] = torch.tensor([0, 1, 0])\n",
    "    model.word_emb.weight[encoder['C']] = torch.tensor([0, 0, 1])\n",
    "hist_emb.append(model.word_emb.weight.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b53b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = components_to_fig_3D_animation(\n",
    "    history_components=hist_emb,\n",
    "    encoder=encoder,\n",
    "    highlight_words=[\"A\", \"B\", \"C\"],\n",
    "    nb_neighbors=0,\n",
    "    base_color=base_color,\n",
    "    _min = -2, _max = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4844591",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = components_to_fig_3D(\n",
    "    components=deepcopy(model.word_emb.weight.detach().numpy()),\n",
    "    encoder=encoder,\n",
    "    highlight_words=[\"A\", \"B\", \"C\", \"R\", \"S\", \"T\"],\n",
    "    nb_neighbors=0,\n",
    "    base_color=base_color\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3472653",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
