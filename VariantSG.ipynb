{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ccaf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataSet import SGNS_store_DataSet\n",
    "\n",
    "from typing import Sequence, Optional, Callable, List, Dict\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "from visuEmbedding import components_to_fig_3D, components_to_fig_3D_animation\n",
    "import tool\n",
    "from data.pipData import pipe_data, prepare_data, prepare_data_with_intonation, separate_text_intonation\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import skew\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from data.pipData import separate_text_intonation\n",
    "from dataSet import W2V_weighted_DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02de2f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGramModel(nn.Module):\n",
    "    def __init__(self, emb_size:int, embedding_dimension:int=15, context_dimension:int|None=None, init_range:float|None=None, sparse:bool=True, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.emb_size:int = emb_size\n",
    "        self.emb_dim:int = embedding_dimension\n",
    "        self.word_emb:nn.Embedding = nn.Embedding(num_embeddings=self.emb_size, embedding_dim=self.emb_dim, device=device, sparse=sparse)\n",
    "        self.con_size = embedding_dimension if context_dimension is None else context_dimension\n",
    "        self.con_emb:nn.Embedding = nn.Embedding(num_embeddings=self.emb_size, embedding_dim=self.con_size, device=device,sparse=sparse)\n",
    "\n",
    "        if init_range is None:\n",
    "            init_range = 0.5 / self.emb_dim\n",
    "        self.word_emb.weight.data.uniform_(-init_range, init_range)\n",
    "        self.con_emb.weight.data.uniform_(-init_range, init_range)\n",
    "\n",
    "    def forward(self, centrals_words:list|torch.Tensor, pos_context:list|torch.Tensor, neg_context:list|torch.Tensor):\n",
    "        words_emb:torch.Tensor = self.word_emb(centrals_words)\n",
    "        context_emb:torch.Tensor = self.con_emb(pos_context) # [B, D]\n",
    "        neg_emb:torch.Tensor = self.con_emb(neg_context) # [B, K, D]\n",
    "\n",
    "        pos_score = torch.sum(words_emb * context_emb, dim=1)\n",
    "        pos_loss = F.logsigmoid(pos_score)\n",
    "\n",
    "        neg_score = torch.bmm(neg_emb, words_emb.unsqueeze(-1)).squeeze(2)\n",
    "        neg_loss = F.logsigmoid(-neg_score).sum(1)\n",
    "\n",
    "        loss = - (pos_loss + neg_loss).mean()\n",
    "        return loss\n",
    "    \n",
    "    def save_weight(self, path:str=\"SGNS_weights/\"):\n",
    "        word_weights = self.word_emb.weight.detach().cpu()\n",
    "        con_weight = self.con_emb.weight.detach().cpu()\n",
    "        torch.save(word_weights, path+'word_embedding.pt')\n",
    "        torch.save(con_weight, path+'con_embedding.pt')\n",
    "\n",
    "    def load_weight(self, path:str=\"SGNS_weights/\", name_word_weights:str=\"word_embedding.pt\", name_con_weights:str=\"con_embedding.pt\"):\n",
    "        word_weights = torch.load(path + name_word_weights)\n",
    "        con_weight = torch.load(path + name_con_weights)\n",
    "        self.word_emb:nn.Embedding = nn.Embedding.from_pretrained(word_weights)\n",
    "        self.con_emb:nn.Embedding = nn.Embedding.from_pretrained(con_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92fd783",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnlyOneEmb(nn.Module):\n",
    "    def __init__(self, emb_size:int, embedding_dimension:int=15, init_range:float|None=None, sparse:bool=True, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.emb_size:int = emb_size\n",
    "        self.emb_dim:int = embedding_dimension\n",
    "        self.word_emb:nn.Embedding = nn.Embedding(num_embeddings=self.emb_size, embedding_dim=self.emb_dim, device=device, sparse=sparse)\n",
    "\n",
    "        if init_range is None:\n",
    "            init_range = 0.5 / self.emb_dim\n",
    "        self.word_emb.weight.data.uniform_(-init_range, init_range)\n",
    "\n",
    "    def forward(self, centrals_words:list|torch.Tensor, pos_context:list|torch.Tensor, neg_context:list|torch.Tensor):\n",
    "        words_emb:torch.Tensor = self.word_emb(centrals_words)\n",
    "        context_emb:torch.Tensor = self.word_emb(pos_context) # [B, D]\n",
    "        neg_emb:torch.Tensor = self.word_emb(neg_context) # [B, K, D]\n",
    "\n",
    "        pos_score = torch.sum(words_emb * context_emb, dim=1)\n",
    "        pos_loss = F.logsigmoid(pos_score)\n",
    "\n",
    "        neg_score = torch.bmm(neg_emb, words_emb.unsqueeze(-1)).squeeze(2)\n",
    "        neg_loss = F.logsigmoid(-neg_score).sum(1)\n",
    "\n",
    "        loss = -(pos_loss + neg_loss).mean()\n",
    "        return loss\n",
    "    \n",
    "    def save_weight(self, path:str=\"SGNS_weights/\"):\n",
    "        word_weights = self.word_emb.weight.detach().cpu()\n",
    "        torch.save(word_weights, path+'word_embedding.pt')\n",
    "\n",
    "    def load_weight(self, path:str=\"SGNS_weights/\", name_word_weights:str=\"word_embedding.pt\"):\n",
    "        word_weights = torch.load(path + name_word_weights)\n",
    "        self.word_emb:nn.Embedding = nn.Embedding.from_pretrained(word_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33719d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGNS_Weighted(nn.Module):\n",
    "    def __init__(self, emb_size:int, embedding_dimension:int=15, init_range:float|None=None, sparse:bool=True, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.emb_size:int = emb_size\n",
    "        self.emb_dim:int = embedding_dimension\n",
    "        self.word_emb:nn.Embedding = nn.Embedding(num_embeddings=self.emb_size, embedding_dim=self.emb_dim, device=device, sparse=sparse)\n",
    "\n",
    "        if init_range is None:\n",
    "            init_range = 0.5 / self.emb_dim\n",
    "        self.word_emb.weight.data.uniform_(-init_range, init_range)\n",
    "\n",
    "    def forward(self, centrals_words:list|torch.Tensor, pos_context:list|torch.Tensor, neg_context:list|torch.Tensor, weights:List|torch.Tensor):\n",
    "        words_emb:torch.Tensor = self.word_emb(centrals_words) # [B, D]\n",
    "        context_emb:torch.Tensor = self.word_emb(pos_context) # [B, D]\n",
    "        neg_emb:torch.Tensor = self.word_emb(neg_context) # [B, K, D]\n",
    "\n",
    "        pos_score = torch.sum(words_emb * context_emb, dim=1)\n",
    "        pos_loss = F.logsigmoid(pos_score)\n",
    "\n",
    "        neg_score = torch.bmm(neg_emb, words_emb.unsqueeze(-1)).squeeze(2)\n",
    "        neg_loss = F.logsigmoid(-neg_score).sum(1)\n",
    "        loss = -((pos_loss + neg_loss) * weights).mean()\n",
    "        \n",
    "        return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d63492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneEmbWeightedTarget(nn.Module):\n",
    "    \"\"\"\n",
    "    This class apply a weight to target word\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, emb_size:int, embedding_dimension:int=15, \n",
    "                init_range:float|None=None, sparse:bool=True, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.emb_size:int = emb_size\n",
    "        self.emb_dim:int = embedding_dimension\n",
    "        self.word_emb:nn.Embedding = nn.Embedding(num_embeddings=self.emb_size, \n",
    "                                                embedding_dim=self.emb_dim, device=device, sparse=sparse)\n",
    "\n",
    "        if init_range is None:\n",
    "            init_range = 0.5 / self.emb_dim\n",
    "        self.word_emb.weight.data.uniform_(-init_range, init_range)\n",
    "\n",
    "    def forward(self, centrals_words:torch.Tensor, pos_context:torch.Tensor,\n",
    "                neg_context:torch.Tensor, weights:torch.Tensor):\n",
    "        words_emb:torch.Tensor = self.word_emb(centrals_words) # [B, D]\n",
    "        context_emb:torch.Tensor = self.word_emb(pos_context) # [B, D]\n",
    "        neg_emb:torch.Tensor = self.word_emb(neg_context) # [B, K, D]\n",
    "        \n",
    "        weights = weights.view(-1, 1)\n",
    "        \n",
    "        def weight_hook(grad):\n",
    "            return grad * weights\n",
    "            \n",
    "        words_emb.register_hook(weight_hook)\n",
    "\n",
    "        pos_score = torch.sum(words_emb * context_emb, dim=1)\n",
    "        pos_loss = F.logsigmoid(pos_score)\n",
    "\n",
    "        neg_score = torch.bmm(neg_emb, words_emb.unsqueeze(-1)).squeeze(2)\n",
    "        neg_loss = F.logsigmoid(-neg_score).sum(1)\n",
    "\n",
    "        loss = -(pos_loss + neg_loss).mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a688d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedTarget(nn.Module):\n",
    "    \"\"\"\n",
    "    This class apply a weight to target word\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, emb_size:int, embedding_dimension:int=15, \n",
    "                init_range:float|None=None, sparse:bool=True, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.emb_size:int = emb_size\n",
    "        self.emb_dim:int = embedding_dimension\n",
    "        self.word_emb:nn.Embedding = nn.Embedding(num_embeddings=self.emb_size, \n",
    "                                                embedding_dim=self.emb_dim, device=device, sparse=sparse)\n",
    "        \n",
    "        self.con_size = embedding_dimension \n",
    "        self.con_emb:nn.Embedding = nn.Embedding(num_embeddings=self.emb_size, \n",
    "                                                 embedding_dim=self.con_size, device=device,sparse=sparse)\n",
    "\n",
    "        if init_range is None:\n",
    "            init_range = 0.5 / self.emb_dim\n",
    "        self.word_emb.weight.data.uniform_(-init_range, init_range)\n",
    "        self.con_emb.weight.data.uniform_(-init_range, init_range)\n",
    "\n",
    "    def forward(self, centrals_words:torch.Tensor, pos_context:torch.Tensor,\n",
    "                neg_context:torch.Tensor, weights:torch.Tensor):\n",
    "        words_emb:torch.Tensor = self.word_emb(centrals_words) # [B, D]\n",
    "        context_emb:torch.Tensor = self.con_emb(pos_context) # [B, D]\n",
    "        neg_emb:torch.Tensor = self.con_emb(neg_context) # [B, K, D]\n",
    "        \n",
    "        weights = weights.view(-1, 1)\n",
    "        \n",
    "        def weight_hook(grad):\n",
    "            return grad * weights\n",
    "            \n",
    "        words_emb.register_hook(weight_hook)\n",
    "\n",
    "        pos_score = torch.sum(words_emb * context_emb, dim=1)\n",
    "        pos_loss = F.logsigmoid(pos_score)\n",
    "\n",
    "        neg_score = torch.bmm(neg_emb, words_emb.unsqueeze(-1)).squeeze(2)\n",
    "        neg_loss = F.logsigmoid(-neg_score).sum(1)\n",
    "\n",
    "        loss = -(pos_loss + neg_loss).mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c2debc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGwithNorm(nn.Module):\n",
    "    def __init__(self, emb_size:int, embedding_dimension:int=15, context_dimension:int|None=None, init_range:float|None=None, sparse:bool=True, device=\"cpu\"):\n",
    "        \"\"\"Initialisation du modèle SkipGram\n",
    "        Args:\n",
    "            emb_size: La taille de l'embedding, ce nombre devrais être déterminé après le process sur les data, et dépend de la taille de la fenêtre glissante.\n",
    "            embedding_dimension: La taille souhaité de l'embedding. Pour notre cas d'utilisation nous préférons une taille très petit\n",
    "            context_dimension: Il n'est pas recommandé de mettre un entier mais de laisser a None.\n",
    "        \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.emb_size:int = emb_size\n",
    "        self.emb_dim:int = embedding_dimension\n",
    "        self.word_emb:nn.Embedding = nn.Embedding(num_embeddings=self.emb_size, embedding_dim=self.emb_dim, device=device, sparse=sparse)\n",
    "\n",
    "        self.con_size = embedding_dimension if context_dimension is None else context_dimension\n",
    "        self.con_emb:nn.Embedding = nn.Embedding(num_embeddings=self.emb_size, embedding_dim=self.con_size, device=device,sparse=sparse)\n",
    "\n",
    "        if init_range is None:\n",
    "            init_range = 0.5 / self.emb_dim\n",
    "        self.word_emb.weight.data.uniform_(-init_range, init_range)\n",
    "        self.con_emb.weight.data.uniform_(-init_range, init_range)\n",
    "\n",
    "        self.scale = nn.Parameter(torch.tensor(10.0, device=device))\n",
    "\n",
    "    def forward(self, centrals_words:list|torch.Tensor, pos_context:list|torch.Tensor, neg_context:list|torch.Tensor):\n",
    "        \"\"\"Fonction du forward pour le modèle SkipGramModel\n",
    "        Args:\n",
    "            centrals_words: Liste des ids des tokens des mots centraux [B]\n",
    "            pos_context: Liste des ids des tokens des mots dans le contexte [B]\n",
    "            neg_context: Liste des ids des tokens des mots non présent dans le contexte [B, K]\n",
    "        \"\"\"\n",
    "        words_emb:torch.Tensor = self.word_emb(centrals_words) # [B, D]\n",
    "        context_emb:torch.Tensor = self.con_emb(pos_context)   # [B, D]\n",
    "        neg_emb:torch.Tensor = self.con_emb(neg_context)       # [B, K, D]\n",
    "        words_norm = F.normalize(words_emb, p=2, dim=1)\n",
    "        context_norm = F.normalize(context_emb, p=2, dim=1)\n",
    "        neg_norm = F.normalize(neg_emb, p=2, dim=2)\n",
    "\n",
    "\n",
    "        pos_dot = torch.sum(words_norm * context_norm, dim=1)\n",
    "        pos_score = pos_dot * self.scale # Scale up\n",
    "        pos_loss = F.logsigmoid(pos_score)\n",
    "\n",
    "        neg_dot = torch.bmm(neg_norm, words_norm.unsqueeze(-1)).squeeze(2)\n",
    "        neg_score = neg_dot * self.scale # Scale up\n",
    "        neg_loss = F.logsigmoid(-neg_score).sum(1)\n",
    "\n",
    "\n",
    "        loss = - (pos_loss + neg_loss).mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70f038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_Word2Vec(modelW2V:nn.Module, dataLoader:Dataset, optimizer:optim.Optimizer, epochs:int, verbal:bool=True, log_interval=100, device=\"cpu\"):\n",
    "    \"\"\"Fonction d’entraînement pour un modèle Word2Vec\n",
    "    \"\"\"\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_loss = 0.0\n",
    "        batches = 0\n",
    "        loss_history = []\n",
    "        global_step = 0\n",
    "        \n",
    "        modelW2V.train()\n",
    "\n",
    "        for batch in dataLoader:\n",
    "            # centers: [B], pos: [B], negs: [B, K]\n",
    "            centers, pos, negs = batch\n",
    "            centers = centers.to(device)\n",
    "            pos = pos.to(device)\n",
    "            negs = negs.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = modelW2V(centers, pos, negs)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_loss = loss.item()\n",
    "            epoch_loss += batch_loss\n",
    "            loss_history.append(batch_loss)\n",
    "            batches += 1\n",
    "            global_step += 1\n",
    "\n",
    "            if verbal and log_interval and (global_step % log_interval == 0):\n",
    "                print(f\"Epoch {epoch} Step {global_step} AvgLoss {epoch_loss / batches:.6f}\")\n",
    "\n",
    "        avg_epoch_loss = epoch_loss / max(1, batches)\n",
    "        if verbal : print(f\"Epoch {epoch} finished. Avg loss: {avg_epoch_loss:.6f}\")\n",
    "\n",
    "    return {\"loss_history\": loss_history, \"final_epoch_loss\": avg_epoch_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602a7774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_matrix(embeddings:nn.Embedding) -> torch.Tensor:\n",
    "    emb = embeddings.weight.detach()\n",
    "    emb_norm = F.normalize(emb, p=2, dim=1)\n",
    "    similarity_matrix = emb_norm @ emb_norm.t()\n",
    "    return similarity_matrix\n",
    "\n",
    "def update_sim_history(words: list[str], idx: List[int], cos_sim_history:Dict, similarity_matrix):\n",
    "    num_words = len(words)\n",
    "\n",
    "    for i in range(num_words):\n",
    "        for j in range(num_words):\n",
    "            similarity = ((similarity_matrix[idx[i], idx[j]] + 1) / 2) * 100\n",
    "            cos_sim_history[words[i]][words[j]].append(round(float(similarity), 2))\n",
    "\n",
    "def heat_map(words:List[str], similarity_matrix, figsize=(10, 8), save_file='tmp.png'):\n",
    "    plt.close('all')\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(similarity_matrix, annot=True, fmt=\".2f\", cmap=\"magma\",\n",
    "                xticklabels=words, yticklabels=words, cbar=True, robust=False,\n",
    "                vmin=0, vmax=100,\n",
    "                square=False, linewidths=0.)\n",
    "\n",
    "    plt.title(\"Matrix de Similarité Cosinus\")\n",
    "    plt.xlabel(\"Mots\", fontstyle=\"italic\")\n",
    "    plt.ylabel(\"Mots\", fontstyle=\"italic\")\n",
    "    plt.savefig(save_file)\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392f25d8",
   "metadata": {},
   "source": [
    "# 1er exp\n",
    "Sur le corpus générer par GPT5, comparé le SGNS avec deux embedding VS un seul embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5842a7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset:SGNS_store_DataSet = pipe_data(\n",
    "    language=\"french\",\n",
    "    dataseteur=SGNS_store_DataSet,\n",
    "    window_size = 3,\n",
    "    nb_neg=5,\n",
    "    subsample_thresh= 1,\n",
    "    vocab_size_limit=None,\n",
    "    file=\"data/GPT5v2.txt\",\n",
    "    remove_accent=True,\n",
    "    remove_ponct=True,\n",
    "    keep_accent= False,\n",
    "    contraction_map=None,\n",
    "    stop_words=[\"le\", \"les\", \"sur\", \"fait\", \"de\", \"et\", \"la\", \"des\", \"sont\"] + \\\n",
    "    [\"the\", \"your\", \"a\", \"rubber\"]\n",
    "\n",
    ")\n",
    "data = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d56788",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [\"chat\", \"chien\", \"animal\", \"animaux\",\"train\", \"balle\", \"jouer\"]\n",
    "\n",
    "modelW2V:SkipGramModel = SkipGramModel(dataset.vocab_size, embedding_dimension=3, init_range=None, sparse=False)\n",
    "# optimizer = torch.optim.SparseAdam(modelW2V.parameters(), lr=0.01)\n",
    "optimizer = torch.optim.Adam(modelW2V.parameters(), lr=0.01)\n",
    "\n",
    "nb_epoch = 30\n",
    "for _ in range(nb_epoch):\n",
    "    for sentence_nb, (centers, pos, negs) in enumerate(data):\n",
    "        optimizer.zero_grad()\n",
    "        loss = modelW2V(centers, pos, negs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "similarity = cosine_similarity_matrix(modelW2V.word_emb)\n",
    "m_to_h = similarity\n",
    "m_to_h = ((m_to_h + 1) / 2) * 100\n",
    "m_to_h_2 = m_to_h[dataset.encode(k),:]\n",
    "m_to_h_2 = m_to_h_2[:, dataset.encode(k)]\n",
    "plt = heat_map(words=k, similarity_matrix=m_to_h_2)\n",
    "plt.show()\n",
    "\n",
    "components_to_fig_3D(components=modelW2V.word_emb.weight.detach().cpu().numpy(),\n",
    "    encoder=dataset.encoder,\n",
    "    words_display=list(dataset.encoder.keys()),\n",
    "    highlight_words=k,\n",
    "    nb_neighbors=2, _min=-5, _max=5, base_color={}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d4cbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelW2V:OnlyOneEmb = OnlyOneEmb(dataset.vocab_size, embedding_dimension=3, init_range=None, sparse=True)\n",
    "# optimizer = torch.optim.Adam(modelW2V.parameters(), lr=0.01)\n",
    "optimizer = torch.optim.SparseAdam(modelW2V.parameters(), lr=0.005)\n",
    "\n",
    "emb_hist = []\n",
    "nb_epoch = 30\n",
    "\n",
    "\n",
    "for _ in range(nb_epoch):\n",
    "    for sentence_nb, (centers, pos, negs) in enumerate(data):\n",
    "        optimizer.zero_grad()\n",
    "        loss = modelW2V(centers, pos, negs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    w = deepcopy(modelW2V.word_emb.weight.detach().cpu().numpy())\n",
    "    emb_hist.append(w)\n",
    "\n",
    "similarity = cosine_similarity_matrix(modelW2V.word_emb)\n",
    "m_to_h = similarity\n",
    "m_to_h = ((m_to_h + 1) / 2) * 100\n",
    "m_to_h_2 = m_to_h[dataset.encode(k),:]\n",
    "m_to_h_2 = m_to_h_2[:, dataset.encode(k)]\n",
    "plt = heat_map(words=k, similarity_matrix=m_to_h_2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0964cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_colors = {\n",
    "    'chat': (\"blue\",  \"cyan\"),\n",
    "    'chien': (\"goldenrod\", \"yellow\"),\n",
    "    'balle': (\"green\", \"lightgreen\"),\n",
    "    \"jouer\": (\"magenta\", \"pink\")\n",
    "}\n",
    "\n",
    "\n",
    "fig = components_to_fig_3D_animation(\n",
    "    history_components=emb_hist,\n",
    "    encoder=dataset.encoder,\n",
    "    highlight_words=[\"chat\", \"chien\", \"balle\", \"jouer\", \"animal\", \"animaux\"],\n",
    "    nb_neighbors=6, base_color=base_colors\n",
    ")\n",
    "\n",
    "tool.DicToJson(dataset.encoder, \"data/encoder\")\n",
    "tool.DicToJson(dataset.decoder, \"data/decoder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ffd9ab",
   "metadata": {},
   "source": [
    "# Teste de fixer des vecteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef188c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelW2V:OnlyOneEmb = OnlyOneEmb(dataset.vocab_size, embedding_dimension=3, init_range=0.5, sparse=True)\n",
    "# optimizer = torch.optim.Adam(modelW2V.parameters(), lr=0.01)\n",
    "optimizer = torch.optim.SparseAdam(modelW2V.parameters(), lr=0.005)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    modelW2V.word_emb.weight[dataset.encoder['animal']] = torch.tensor([1, 0, 0.3])\n",
    "    modelW2V.word_emb.weight[dataset.encoder['train']] = torch.tensor([-1, 0, 0])\n",
    "\n",
    "emb_hist = []\n",
    "nb_epoch = 10\n",
    "\n",
    "w = deepcopy(modelW2V.word_emb.weight.detach().cpu().numpy())\n",
    "emb_hist.append(w)\n",
    "for _ in range(nb_epoch):\n",
    "    for sentence_nb, (centers, pos, negs) in enumerate(data):\n",
    "        optimizer.zero_grad()\n",
    "        loss = modelW2V(centers, pos, negs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    with torch.no_grad():\n",
    "        modelW2V.word_emb.weight[dataset.encoder['animal']] = torch.tensor([1, 0, 0.3])\n",
    "        \n",
    "    w = deepcopy(modelW2V.word_emb.weight.detach().cpu().numpy())\n",
    "    emb_hist.append(w)\n",
    "\n",
    "similarity = cosine_similarity_matrix(modelW2V.word_emb)\n",
    "m_to_h = similarity\n",
    "m_to_h = ((m_to_h + 1) / 2) * 100\n",
    "m_to_h_2 = m_to_h[dataset.encode(k),:]\n",
    "m_to_h_2 = m_to_h_2[:, dataset.encode(k)]\n",
    "plt = heat_map(words=k, similarity_matrix=m_to_h_2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324ffd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = components_to_fig_3D_animation(\n",
    "    history_components=emb_hist,\n",
    "    encoder=dataset.encoder,\n",
    "    highlight_words=[\"chat\", \"chien\", \"train\", \"jouer\", \"animal\", \"animaux\"],\n",
    "    nb_neighbors=6, base_color=base_colors\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e53be4d",
   "metadata": {},
   "source": [
    "# Nouveau data set, GoodNightGorilla \n",
    "Corpus plus riche et en lien avec un livre pour enfant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d722afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset:SGNS_store_DataSet = pipe_data(\n",
    "    language=\"english\",\n",
    "    dataseteur=SGNS_store_DataSet,\n",
    "    window_size = 3,\n",
    "    nb_neg=5,\n",
    "    subsample_thresh= 1,\n",
    "    vocab_size_limit=None,\n",
    "    file=\"data/GoodNightGorilla.txt\",\n",
    "    remove_accent=True,\n",
    "    remove_ponct=True,\n",
    "    keep_accent= False,\n",
    "    contraction_map=None,\n",
    "    stop_words=[]\n",
    "\n",
    ")\n",
    "data = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3a0116",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.__len__())\n",
    "counter = Counter()\n",
    "for centers, _, _ in data:\n",
    "    ids = centers.flatten().tolist() if hasattr(centers, \"flatten\") else list(centers)\n",
    "    for idx in ids:\n",
    "        counter[dataset.decoder[int(idx)]] += 1\n",
    "\n",
    "freq_central_words = dict(counter.most_common())\n",
    "print(freq_central_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd497458",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelW2V:OnlyOneEmb = OnlyOneEmb(dataset.vocab_size, embedding_dimension=3,\n",
    "\t\t\t\t\t\t\t\tinit_range=None, sparse=True)\n",
    "modelW2V_2Emb:SkipGramModel = SkipGramModel(dataset.vocab_size, embedding_dimension=3,\n",
    "\t\t\t\t\t\t\t\tinit_range=None, sparse=True)\n",
    "optimizer = torch.optim.SparseAdam(modelW2V.parameters(), lr=0.005)\n",
    "optimizer_2Emb = torch.optim.SparseAdam(modelW2V_2Emb.parameters(), lr=0.005)\n",
    "\n",
    "emb_hist = []\n",
    "nb_epoch = 5\n",
    "\n",
    "for _ in range(nb_epoch):\n",
    "\tfor sentence_nb, (centers, pos, negs) in enumerate(data):\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\toptimizer_2Emb.zero_grad()\n",
    "\t\tloss = modelW2V(centers, pos, negs)\n",
    "\t\tloss.backward()\n",
    "\t\tloss_2Emb = modelW2V_2Emb(centers, pos, negs)\n",
    "\t\tloss_2Emb.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\toptimizer_2Emb.step()\n",
    " \n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e52aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [\"gorilla\", \"animals\", \"mouse\", \"monkey\", \"he\", \"say\", \"the\", \"zookeeper\"]\n",
    "\n",
    "similarity = cosine_similarity_matrix(modelW2V.word_emb)\n",
    "m_to_h = similarity\n",
    "m_to_h = ((m_to_h + 1) / 2) * 100\n",
    "m_to_h_2 = m_to_h[dataset.encode(k),:]\n",
    "m_to_h_2 = m_to_h_2[:, dataset.encode(k)]\n",
    "plt = heat_map(words=k, similarity_matrix=m_to_h_2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d9e102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_neighbors(vector_word:torch.Tensor, tensor:torch.Tensor, top_n:int=5):\n",
    "    all_scores = cosine_similarity(tensor, vector_word.reshape(1, -1))\n",
    "    score_series = pd.Series(all_scores.flatten())\n",
    "    top_words = score_series.sort_values(ascending=False).head(top_n)\n",
    "    return top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f5fbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_of_similarity = cosine_similarity_matrix(modelW2V.word_emb)\n",
    "word_a = \"banana\"\n",
    "nearest_neighbors = find_nearest_neighbors(matrix_of_similarity[dataset.encode(word_a)], matrix_of_similarity,\n",
    "                                            top_n=20)\n",
    "nearest_neighbors = nearest_neighbors.rename(index=lambda x: dataset.decoder[x])\n",
    "print(f\"Nearest Neighbors to '{word_a}':\")\n",
    "print(nearest_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a604a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_a = \"gorilla\"\n",
    "nearest_neighbors = find_nearest_neighbors(matrix_of_similarity[dataset.encode(word_a)], matrix_of_similarity,\n",
    "                                            top_n=20)\n",
    "nearest_neighbors = nearest_neighbors.rename(index=lambda x: dataset.decoder[x])\n",
    "print(f\"Nearest Neighbors to '{word_a}':\")\n",
    "print(nearest_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a2baa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = modelW2V.word_emb.weight.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b7fa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool.analyser_anisotropie_advanced(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49c86fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelW2V.save_weight(\"SGNS_weights/OneEmb/GoodNightGorilla\")\n",
    "tool.DicToJson(dataset.encoder, 'data/encoder')\n",
    "tool.DicToJson(dataset.decoder, 'data/decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897685a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "norms = torch.linalg.vector_norm(modelW2V.word_emb.weight, dim=1)\n",
    "print(norms.mean(), norms.std())\n",
    "\n",
    "df_norm_vecteur = pd.DataFrame(norms.detach().numpy(), columns=['Norme des Vecteurs'], index=sorted(list(dataset.encoder.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52bcc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "norms_2emb = torch.linalg.vector_norm(modelW2V_2Emb.word_emb.weight, dim=1)\n",
    "print(norms_2emb.mean(), norms_2emb.std())\n",
    "\n",
    "df_norm_vecteur_2emb = pd.DataFrame(norms_2emb.detach().numpy(), columns=['Norme des Vecteurs'], index=sorted(list(dataset.encoder.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f52282",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [\"banana\", \"yellow\", \"mouse\", \"he\", \"the\", \"zookeeper\"]\n",
    "\n",
    "components_to_fig_3D(components=modelW2V.word_emb.weight.detach().cpu().numpy(),\n",
    "    encoder=dataset.encoder,\n",
    "    words_display=list(dataset.encoder.keys()),\n",
    "    highlight_words=k,\n",
    "    nb_neighbors=11, base_color={}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a2f0d1",
   "metadata": {},
   "source": [
    "# Intonation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48c9da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_data_with_intonation(\n",
    "    file_path=\"./data/GoodNightGorilla_Intonation.txt\",\n",
    "    language='english',\n",
    "    remove_accent=True,\n",
    "    remove_punct=True,\n",
    "    keep_apostrophes=False,\n",
    "    contraction_map={\n",
    "        \"that's\" : \"thatis\",\n",
    "        \"it's\" : \"itis\",\n",
    "        \"don't\": \"donot\",\n",
    "        \"doesn't\": \"doesnot\",},\n",
    "    stop_words=[\"s\", \"n't\"],\n",
    "    break_line=False\n",
    ")\n",
    "\n",
    "texts, intonations = separate_text_intonation(data)\n",
    "data_set = W2V_weighted_DataSet(sentences=texts, intonations=intonations)\n",
    "loader = DataLoader(data_set, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8fb286",
   "metadata": {},
   "source": [
    "## Analyse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c411b456",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pair = data_set.pairs\n",
    "word_central = []\n",
    "word_context = []\n",
    "word_intonat = []\n",
    "for w_cen, w_con, into in all_pair:\n",
    "    word_central.append(w_cen)\n",
    "    word_context.append(w_con)\n",
    "    word_intonat.append(into)\n",
    "\n",
    "freq_cent = Counter(word_central)\n",
    "freq_cont = Counter(word_context)\n",
    "print(freq_cent.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cd2c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelW2V:SGNS_Weighted = SGNS_Weighted(len(data_set.encoder.values()), embedding_dimension=3)\n",
    "optimizer = torch.optim.SparseAdam(modelW2V.parameters(), lr=0.005)\n",
    "\n",
    "nb_epoch = 5\n",
    "w = deepcopy(modelW2V.word_emb.weight.detach().cpu().numpy())\n",
    "emb_hist = [w]\n",
    "\n",
    "for _ in range(nb_epoch):\n",
    "\tfor sentence_nb, (centers, pos, negs, intonation) in enumerate(loader):\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss = modelW2V(centers, pos, negs, intonation)\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\tw = deepcopy(modelW2V.word_emb.weight.detach().cpu().numpy())\n",
    "\temb_hist.append(w)\n",
    " \n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef92e127",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = components_to_fig_3D_animation(\n",
    "    history_components=emb_hist,\n",
    "    encoder=data_set.encoder,\n",
    "    highlight_words=[\"banana\", \"gorilla\", \"little\", \"yellow\", \"zookeeper\"],\n",
    "    nb_neighbors=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7deb8c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = components_to_fig_3D_animation(\n",
    "    history_components=emb_hist,\n",
    "    encoder=data_set.encoder,\n",
    "    highlight_words=[\"banana\", \"gorilla\", \"little\", \"yellow\", \"zookeeper\"],\n",
    "    nb_neighbors=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e190009",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_without_0intonation = []\n",
    "intonation_without_0intonation = []\n",
    "\n",
    "for sentence_t, sentence_i in zip(texts, intonations):\n",
    "    text_without_0intonation.append([])\n",
    "    intonation_without_0intonation.append([])\n",
    "    for t, i in zip(sentence_t, sentence_i):\n",
    "        if int(i) != 0:\n",
    "            text_without_0intonation[-1].append(t)\n",
    "            intonation_without_0intonation[-1].append(i)\n",
    "            \n",
    "data_set_2 = W2V_weighted_DataSet(sentences=text_without_0intonation, intonations=intonation_without_0intonation)\n",
    "loader_2 = DataLoader(data_set_2, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f63b0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelW2V_w0:SGNS_Weighted = SGNS_Weighted(len(data_set.encoder.values()), embedding_dimension=3, device=\"cuda\")\n",
    "optimizer_w0 = torch.optim.SparseAdam(modelW2V_w0.parameters(), lr=0.01)\n",
    "\n",
    "nb_epoch = 5\n",
    "for _ in range(nb_epoch):\n",
    "\tfor sentence_nb, (center, pos, negs, intonation) in enumerate(loader):\n",
    "\t\tcenter = center.to(\"cuda\")\n",
    "\t\tpos = pos.to(\"cuda\")\n",
    "\t\tnegs = negs.to(\"cuda\")\n",
    "\t\tintonation = intonation.to(\"cuda\")\n",
    "\t\toptimizer_w0.zero_grad()\n",
    "\t\tloss = modelW2V_w0(center, pos, negs, intonation)\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer_w0.step()\n",
    " \n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df3bb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = components_to_fig_3D_animation(\n",
    "    history_components=[modelW2V_w0.word_emb.weight.cpu().detach().numpy()],\n",
    "    encoder=data_set_2.encoder,\n",
    "    highlight_words=[\"banana\", \"gorilla\", \"little\", \"yellow\", \"zookeeper\"],\n",
    "    nb_neighbors=6\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b069ebd",
   "metadata": {},
   "source": [
    "# Normalize intonation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d95153",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_data_with_intonation(\n",
    "    file_path=\"./data/GoodNightGorilla_Intonation.txt\",\n",
    "    language='english',\n",
    "    remove_accent=True,\n",
    "    remove_punct=True,\n",
    "    keep_apostrophes=False,\n",
    "    contraction_map={\n",
    "        \"that's\" : \"thatis\",\n",
    "        \"it's\" : \"itis\",\n",
    "        \"don't\": \"donot\",\n",
    "        \"doesn't\": \"doesnot\",},\n",
    "    stop_words=[\"s\", \"n't\"],\n",
    "    break_line=False\n",
    ")\n",
    "\n",
    "texts, intonations = separate_text_intonation(data)\n",
    "\n",
    "intonations = tool.normalize_range_center(intonations, range_normalize=1.5, center=2.0)\n",
    "print(intonations)\n",
    "\n",
    "data_set:W2V_weighted_DataSet = W2V_weighted_DataSet(sentences=texts, intonations=intonations, nb_neg=3, window_size=6)\n",
    "distribution = data_set.unigram_dist\n",
    "\n",
    "all_token = []\n",
    "for sentence in data_set.tokens:\n",
    "    all_token.extend(sentence)\n",
    "    \n",
    "freq = Counter(all_token)\n",
    "freq_list = [freq.get(i, 0) for i in range(len(data_set.decoder.keys()))]\n",
    "\n",
    "unigram = torch.tensor([f**0.75 for f in freq_list], dtype=torch.float)\n",
    "unigram = unigram / unigram.sum()\n",
    "\n",
    "for w, idx in data_set.encoder.items():\n",
    "    print(f\"word :{w} frequencies : {freq_list[idx]}, probability {unigram[idx]}\")\n",
    "\n",
    "data_set.unigram_dist = unigram\n",
    "\n",
    "loader = DataLoader(data_set, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b35a7b",
   "metadata": {},
   "source": [
    "## Analyse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db82729",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pair = data_set.pairs\n",
    "word_central = []\n",
    "word_context = []\n",
    "word_intonat = []\n",
    "for w_cen, w_con, into in all_pair:\n",
    "    word_central.append(data_set.decode(w_cen))\n",
    "    word_context.append(data_set.decode(w_con))\n",
    "\n",
    "freq_cent = Counter(word_central)\n",
    "freq_cont = Counter(word_context)\n",
    "print(freq_cent.most_common())\n",
    "print(freq_cont.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723aa15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_importance = data_set.word_importance\n",
    "   \n",
    "word_neg = []\n",
    "for _, _, batch_neg, _ in loader:\n",
    "    for neg in batch_neg:\n",
    "        word_neg.extend(neg.tolist())\n",
    "\n",
    "print(word_neg)\n",
    "word_neg = data_set.decode(word_neg)\n",
    "freq_neg = Counter(word_neg)\n",
    "df_freq_neg = (pd.DataFrame.from_dict(freq_neg, orient='index', columns=['count'])\n",
    "               .reset_index()\n",
    "               .rename(columns={'index': 'word'})\n",
    "               .sort_values('count', ascending=False)\n",
    "               .reset_index(drop=True))\n",
    "df_freq_neg.head()\n",
    "print(next(zip(*freq_neg.most_common(5))))\n",
    "freq_neg.most_common(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6186ea80",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelW2V:SGNS_Weighted = SGNS_Weighted(len(data_set.encoder.values()), embedding_dimension=3)\n",
    "optimizer = torch.optim.SparseAdam(modelW2V.parameters(), lr=0.00001)\n",
    "\n",
    "nb_epoch = 10\n",
    "w = deepcopy(modelW2V.word_emb.weight.detach().cpu().numpy())\n",
    "emb_hist = [w]\n",
    "\n",
    "for _ in range(nb_epoch):\n",
    "\tfor sentence_nb, (centers, pos, negs, intonation) in enumerate(loader):\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss = modelW2V(centers, pos, negs, intonation)\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\tw = deepcopy(modelW2V.word_emb.weight.detach().cpu().numpy())\n",
    "\temb_hist.append(w)\n",
    " \n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f699261",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_colors = {\n",
    "    'banana': (\"yellow\",  \"lightyellow\"),\n",
    "    'gorilla': (\"gray\", \"lightgray\"),\n",
    "    'zookeeper': (\"brown\", \"sandybrown\"),\n",
    "    \"little\": (\"pink\", \"lightpink\"),\n",
    "    \"yellow\": (\"gold\", \"lightgoldenrodyellow\")\n",
    "}\n",
    "\n",
    "# histo_emb_norm = [] # Normalisation PCA for embedding > 3\n",
    "# for emb in emb_hist:\n",
    "#     pca = PCA(n_components=3)\n",
    "#     X = pca.fit_transform(emb)\n",
    "#     histo_emb_norm.append(X)\n",
    "    \n",
    "# fig = components_to_fig_3D_animation(\n",
    "#     history_components=histo_emb_norm,\n",
    "#     encoder=data_set.encoder,\n",
    "#     highlight_words=[\"banana\", \"gorilla\", \"little\", \"yellow\", \"zookeeper\"],\n",
    "#     nb_neighbors=1, base_color=base_colors\n",
    "# )\n",
    "\n",
    "fig = components_to_fig_3D_animation( # for embedding = 3\n",
    "    history_components=emb_hist,\n",
    "    encoder=data_set.encoder,\n",
    "    highlight_words=next(zip(*freq_neg.most_common(5))),\n",
    "    nb_neighbors=1, base_color=base_colors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9746140c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "\n",
    "for pair in loader:\n",
    "    centers, pos, negs, intonation = pair\n",
    "    for c, p, n, i in zip(centers, pos, negs, intonation):\n",
    "        word_c = data_set.decoder[int(c)]\n",
    "        word_p = data_set.decoder[int(p)]\n",
    "        words_n = [data_set.decoder[int(idx)] for idx in n]\n",
    "        pairs.append((word_c, word_p, words_n, float(i)))\n",
    "        \n",
    "        \n",
    "norm_all_vec = torch.linalg.vector_norm(modelW2V.word_emb.weight, dim=1)\n",
    "print(norm_all_vec.mean(), norm_all_vec.std())\n",
    "\n",
    "df_norm_vecteur = pd.DataFrame(norm_all_vec.detach().numpy(), columns=['Norme des Vecteurs'], index=list(data_set.encoder.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857005aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelW2V:OnlyOneEmb = OneEmbWeightedTarget(len(data_set.pairs), embedding_dimension=3, device=\"cuda\")\n",
    "optimizer = torch.optim.SparseAdam(modelW2V.parameters(), lr=0.0001)\n",
    "\n",
    "nb_epoch = 50\n",
    "w = deepcopy(modelW2V.word_emb.weight.detach().cpu().numpy())\n",
    "emb_hist = [w]\n",
    "\n",
    "all_loss = []\n",
    "\n",
    "for _ in range(nb_epoch):\n",
    "\tloss_inter = []\n",
    "\tfor sentence_nb, (centers, pos, negs, intonation) in enumerate(loader):\n",
    "\t\toptimizer.zero_grad()\n",
    "  \n",
    "\t\tintonation = intonation.float().to(\"cuda\")\n",
    "  \n",
    "\t\tcenters = centers.to(\"cuda\")\n",
    "\t\tpos = pos.to(\"cuda\")\n",
    "\t\tnegs = negs.to(\"cuda\")\n",
    "\n",
    "\t\tloss = modelW2V(centers, pos, negs, intonation)\n",
    "\t\tloss.backward()\n",
    "\t\tloss_inter.append(float(loss))\n",
    "\t\toptimizer.step()\n",
    "\tall_loss.append(sum(loss_inter) / len(loss_inter))\n",
    "\tw = deepcopy(modelW2V.word_emb.weight.detach().cpu().numpy())\n",
    "\temb_hist.append(w)\n",
    " \n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab43a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7b149f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_colors = {\n",
    "    'banana': (\"yellow\",  \"lightyellow\"),\n",
    "    'gorilla': (\"gray\", \"lightgray\"),\n",
    "    'zookeeper': (\"brown\", \"sandybrown\"),\n",
    "    \"little\": (\"pink\", \"lightpink\"),\n",
    "    \"yellow\": (\"gold\", \"lightgoldenrodyellow\")\n",
    "}\n",
    "\n",
    "# histo_emb_norm = [] # Normalisation PCA for embedding > 3\n",
    "# for emb in emb_hist:\n",
    "#     pca = PCA(n_components=3)\n",
    "#     X = pca.fit_transform(emb)\n",
    "#     histo_emb_norm.append(X)\n",
    "    \n",
    "# fig = components_to_fig_3D_animation(\n",
    "#     history_components=histo_emb_norm,\n",
    "#     encoder=data_set.encoder,\n",
    "#     highlight_words=[\"banana\", \"gorilla\", \"little\", \"yellow\", \"zookeeper\"],\n",
    "#     nb_neighbors=11, base_color=base_colors\n",
    "# )\n",
    "\n",
    "fig = components_to_fig_3D_animation( # for embedding = 3\n",
    "    history_components=emb_hist,\n",
    "    encoder=data_set.encoder,\n",
    "    highlight_words=[\"banana\", \"gorilla\", \"mouse\", \"little\", \"yellow\", \"zookeeper\"],\n",
    "    nb_neighbors=11, base_color=base_colors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308345d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "\n",
    "for pair in loader:\n",
    "    centers, pos, negs, intonation = pair\n",
    "    for c, p, n, i in zip(centers, pos, negs, intonation):\n",
    "        word_c = data_set.decoder[int(c)]\n",
    "        word_p = data_set.decoder[int(p)]\n",
    "        words_n = [data_set.decoder[int(idx)] for idx in n]\n",
    "        pairs.append((word_c, word_p, words_n, float(i)))\n",
    "        \n",
    "        \n",
    "norm_all_vec = torch.linalg.vector_norm(modelW2V.word_emb.weight, dim=1)\n",
    "print(norm_all_vec.mean(), norm_all_vec.std())\n",
    "\n",
    "df_norm_vecteur = pd.DataFrame(norm_all_vec.detach().cpu().numpy(), \n",
    "                               columns=['Norme des Vecteurs'], index=list(data_set.encoder.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bcf4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelW2V:WeightedTarget = WeightedTarget(len(data_set.pairs), embedding_dimension=3, device=\"cuda\")\n",
    "optimizer = torch.optim.SparseAdam(modelW2V.parameters(), lr=0.001)\n",
    "\n",
    "nb_epoch = 20\n",
    "w = deepcopy(modelW2V.word_emb.weight.detach().cpu().numpy())\n",
    "emb_hist = [w]\n",
    "\n",
    "for _ in range(nb_epoch):\n",
    "\tfor sentence_nb, (centers, pos, negs, intonation) in enumerate(loader):\n",
    "\t\toptimizer.zero_grad()\n",
    "  \n",
    "\t\tintonation = intonation.float().to(\"cuda\")\n",
    "  \n",
    "\t\tcenters = centers.to(\"cuda\")\n",
    "\t\tpos = pos.to(\"cuda\")\n",
    "\t\tnegs = negs.to(\"cuda\")\n",
    "\n",
    "\t\tloss = modelW2V(centers, pos, negs, intonation)\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\tw = deepcopy(modelW2V.word_emb.weight.detach().cpu().numpy())\n",
    "\temb_hist.append(w)\n",
    " \n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d96f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_colors = {\n",
    "    'banana': (\"yellow\",  \"lightyellow\"),\n",
    "    'gorilla': (\"gray\", \"lightgray\"),\n",
    "    'zookeeper': (\"brown\", \"sandybrown\"),\n",
    "    \"little\": (\"pink\", \"lightpink\"),\n",
    "    \"yellow\": (\"gold\", \"lightgoldenrodyellow\")\n",
    "}\n",
    "\n",
    "# histo_emb_norm = [] # Normalisation PCA for embedding > 3\n",
    "# for emb in emb_hist:\n",
    "#     pca = PCA(n_components=3)\n",
    "#     X = pca.fit_transform(emb)\n",
    "#     histo_emb_norm.append(X)\n",
    "    \n",
    "# fig = components_to_fig_3D_animation(\n",
    "#     history_components=histo_emb_norm,\n",
    "#     encoder=data_set.encoder,\n",
    "#     highlight_words=[\"banana\", \"gorilla\", \"little\", \"yellow\", \"zookeeper\"],\n",
    "#     nb_neighbors=1, base_color=base_colors\n",
    "# )\n",
    "\n",
    "fig = components_to_fig_3D_animation( # for embedding = 3\n",
    "    history_components=emb_hist,\n",
    "    encoder=data_set.encoder,\n",
    "    highlight_words=[\"banana\", \"gorilla\", \"little\", \"yellow\", \"zookeeper\"],\n",
    "    nb_neighbors=11, base_color=base_colors\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
